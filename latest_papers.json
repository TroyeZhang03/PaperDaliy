[
  {
    "title": "RAVEN: Erasing Invisible Watermarks via Novel View Synthesis",
    "url": "http://arxiv.org/abs/2601.08832v1",
    "abstract_en": "Invisible watermarking has become a critical mechanism for authenticating AI-generated image content, with major platforms deploying watermarking schemes at scale. However, evaluating the vulnerability of these schemes against sophisticated removal attacks remains essential to assess their reliability and guide robust design. In this work, we expose a fundamental vulnerability in invisible watermarks by reformulating watermark removal as a view synthesis problem. Our key insight is that generating a perceptually consistent alternative view of the same semantic content, akin to re-observing a scene from a shifted perspective, naturally removes the embedded watermark while preserving visual fidelity. This reveals a critical gap: watermarks robust to pixel-space and frequency-domain attacks remain vulnerable to semantic-preserving viewpoint transformations. We introduce a zero-shot diffusion-based framework that applies controlled geometric transformations in latent space, augmented with view-guided correspondence attention to maintain structural consistency during reconstruction. Operating on frozen pre-trained models without detector access or watermark knowledge, our method achieves state-of-the-art watermark suppression across 15 watermarking methods--outperforming 14 baseline attacks while maintaining superior perceptual quality across multiple datasets.",
    "date": "2026-01-13",
    "summary_cn": "本研究揭示了当前不可见水印方案的一个根本性漏洞，即其难以抵抗保持语义内容的视角变换攻击。作者将水印去除问题重新定义为视角合成问题，提出了一种零样本扩散框架，在潜在空间中施加受控的几何变换，并利用视角引导的注意力机制来维持图像结构。该方法无需访问水印检测器或水印知识，在多个数据集上对15种水印方法实现了最先进的去除效果，同时保持了优异的视觉质量。",
    "one_sentence": "本文提出了一种基于零样本扩散模型和视角合成思想的攻击方法，通过生成语义一致的新视角图像来有效去除多种不可见水印。"
  },
  {
    "title": "3AM: Segment Anything with Geometric Consistency in Videos",
    "url": "http://arxiv.org/abs/2601.08831v1",
    "abstract_en": "Video object segmentation methods like SAM2 achieve strong performance through memory-based architectures but struggle under large viewpoint changes due to reliance on appearance features. Traditional 3D instance segmentation methods address viewpoint consistency but require camera poses, depth maps, and expensive preprocessing. We introduce 3AM, a training-time enhancement that integrates 3D-aware features from MUSt3R into SAM2. Our lightweight Feature Merger fuses multi-level MUSt3R features that encode implicit geometric correspondence. Combined with SAM2's appearance features, the model achieves geometry-consistent recognition grounded in both spatial position and visual similarity. We propose a field-of-view aware sampling strategy ensuring frames observe spatially consistent object regions for reliable 3D correspondence learning. Critically, our method requires only RGB input at inference, with no camera poses or preprocessing. On challenging datasets with wide-baseline motion (ScanNet++, Replica), 3AM substantially outperforms SAM2 and extensions, achieving 90.6% IoU and 71.7% Positive IoU on ScanNet++'s Selected Subset, improving over state-of-the-art VOS methods by +15.9 and +30.4 points. Project page: https://jayisaking.github.io/3AM-Page/",
    "date": "2026-01-13",
    "summary_cn": "针对现有视频目标分割方法在大视角变化下表现不佳的问题，本文提出了3AM方法。该方法在训练时将MUSt3R提供的3D感知特征与SAM2的外观特征进行轻量级融合，并采用视场感知采样策略确保几何对应学习的可靠性。推理时仅需RGB输入，无需相机位姿或深度图预处理。在ScanNet++等具有宽基线运动的挑战性数据集上，3AM显著超越了SAM2等先进方法，性能提升显著。",
    "one_sentence": "本文提出了一种名为3AM的训练时增强方法，通过将编码隐式几何对应的3D感知特征与SAM2的外观特征融合，实现了仅需RGB输入即可在视角大变化下进行几何一致性的视频目标分割。"
  },
  {
    "title": "Forbidden second harmonics in centrosymmetric bilayer crystals",
    "url": "http://arxiv.org/abs/2601.08830v1",
    "abstract_en": "Optical spectroscopy based on second-order nonlinearity is a critical technique for characterizing two-dimensional (2D) crystals as well as bioimaging and quantum optics. It is generally believed that second-harmonic generation (SHG) in centrosymmetric crystals, such as graphene and other bilayer 2D crystals, is negligible without externally breaking the inversion symmetry. Here, we show that with a new homodyne detection technique, we can apparently circumvent this symmetry-imposed constraint and observe robust SHG in pristine centrosymmetric crystals, without any symmetry-breaking field. With its exceptional sensitivity, we resolve polarization-resolved SHG in bilayer hexagonal boron nitride (h-BN), bilayer 2H-WSe$_2$, and remarkably, Bernal-stacked bilayer graphene, allowing us to unambiguously identify the crystallographic orientation in these crystals via SHG for the first time. We also demonstrate that the new technique can be used to non-invasively detect uniaxial strain and optical geometric phase in these crystals. The observed SHG in our experiments is attributed to second-order nonlinearity in the quadrupole channel, which is controlled by the presence of the $C_2$ symmetry instead of the inversion symmetry. Our new technique expands the capability of nonlinear optical spectroscopy to encompass a large class of centrosymmetric materials that could never be measured before, and can be used for quantum sensing of moiré materials and twisted epitaxial films.",
    "date": "2026-01-13",
    "summary_cn": "传统观点认为，如石墨烯等中心对称晶体的二阶谐波产生（SHG）在无外部对称性破缺时极弱。本研究采用一种新型高灵敏度零差检测技术，首次在原始双层六方氮化硼、2H-WSe2及伯纳尔堆叠双层石墨烯等中心对称晶体中观测到了显著的SHG信号，并实现了晶体学取向的明确识别。该技术还可用于检测单轴应变和光学几何相位，其SHG源于四极矩通道的二阶非线性，受C2对称性而非反演对称性控制。这项技术极大扩展了非线性光谱学的应用范围，可用于莫尔材料等量子传感。",
    "one_sentence": "本文提出了一种新型零差检测技术，首次在无需破坏对称性的原始中心对称晶体（如双层石墨烯）中观测到了稳健的二阶谐波产生，突破了传统对称性约束。"
  },
  {
    "title": "Modeling LLM Agent Reviewer Dynamics in Elo-Ranked Review System",
    "url": "http://arxiv.org/abs/2601.08829v1",
    "abstract_en": "In this work, we explore the Large Language Model (LLM) agent reviewer dynamics in an Elo-ranked review system using real-world conference paper submissions. Multiple LLM agent reviewers with different personas are engage in multi round review interactions moderated by an Area Chair. We compare a baseline setting with conditions that incorporate Elo ratings and reviewer memory. Our simulation results showcase several interesting findings, including how incorporating Elo improves Area Chair decision accuracy, as well as reviewers' adaptive review strategy that exploits our Elo system without improving review effort. Our code is available at https://github.com/hsiangwei0903/EloReview.",
    "date": "2026-01-13",
    "summary_cn": "本研究利用真实会议论文数据，模拟了一个由领域主席主持、多个具有不同角色的LLM智能体评审员参与的Elo排名评审系统。通过对比基线设置与引入Elo评分和评审记忆的条件，模拟结果发现：融入Elo评分能提高领域主席决策的准确性，同时评审员会发展出利用Elo系统但不增加评审努力的自适应策略。",
    "one_sentence": "本文提出了一种在基于Elo排名的同行评审系统中引入多智能体LLM评审员进行模拟研究的方法，揭示了融入Elo评分如何影响评审决策准确性和评审策略。"
  },
  {
    "title": "Motion Attribution for Video Generation",
    "url": "http://arxiv.org/abs/2601.08828v1",
    "abstract_en": "Despite the rapid progress of video generation models, the role of data in influencing motion is poorly understood. We present Motive (MOTIon attribution for Video gEneration), a motion-centric, gradient-based data attribution framework that scales to modern, large, high-quality video datasets and models. We use this to study which fine-tuning clips improve or degrade temporal dynamics. Motive isolates temporal dynamics from static appearance via motion-weighted loss masks, yielding efficient and scalable motion-specific influence computation. On text-to-video models, Motive identifies clips that strongly affect motion and guides data curation that improves temporal consistency and physical plausibility. With Motive-selected high-influence data, our method improves both motion smoothness and dynamic degree on VBench, achieving a 74.1% human preference win rate compared with the pretrained base model. To our knowledge, this is the first framework to attribute motion rather than visual appearance in video generative models and to use it to curate fine-tuning data.",
    "date": "2026-01-13",
    "summary_cn": "本文提出了Motive框架，这是一个专门用于分析视频生成模型中数据如何影响运动属性的方法。它通过运动加权的损失掩码将时序动态与静态外观分离，实现了高效、可扩展的运动特异性影响力计算。该框架能够识别出对运动质量有显著影响的训练片段，并以此指导数据筛选。实验表明，使用Motive筛选的高影响力数据进行微调，能有效提升生成视频的运动平滑度和动态程度，在人类评估中获得了74.1%的偏好胜率。",
    "one_sentence": "本文提出了首个针对视频生成模型运动属性的数据溯源框架Motive，通过基于梯度的运动影响力计算来指导数据筛选，从而提升生成视频的时序一致性和物理合理性。"
  }
]