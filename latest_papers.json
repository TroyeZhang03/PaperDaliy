[
  {
    "title": "Stream-DiffVSR: Low-Latency Streamable Video Super-Resolution via Auto-Regressive Diffusion",
    "url": "http://arxiv.org/abs/2512.23709v1",
    "abstract_en": "Diffusion-based video super-resolution (VSR) methods achieve strong perceptual quality but remain impractical for latency-sensitive settings due to reliance on future frames and expensive multi-step denoising. We propose Stream-DiffVSR, a causally conditioned diffusion framework for efficient online VSR. Operating strictly on past frames, it combines a four-step distilled denoiser for fast inference, an Auto-regressive Temporal Guidance (ARTG) module that injects motion-aligned cues during latent denoising, and a lightweight temporal-aware decoder with a Temporal Processor Module (TPM) that enhances detail and temporal coherence. Stream-DiffVSR processes 720p frames in 0.328 seconds on an RTX4090 GPU and significantly outperforms prior diffusion-based methods. Compared with the online SOTA TMP, it boosts perceptual quality (LPIPS +0.095) while reducing latency by over 130x. Stream-DiffVSR achieves the lowest latency reported for diffusion-based VSR, reducing initial delay from over 4600 seconds to 0.328 seconds, thereby making it the first diffusion VSR method suitable for low-latency online deployment. Project page: https://jamichss.github.io/stream-diffvsr-project-page/",
    "date": "2025-12-29",
    "summary_cn": "AI 接口暂时不可用，请阅读下方英文摘要。",
    "one_sentence": "生成失败"
  },
  {
    "title": "Quantum Geometric Bounds in Non-Hermitian Systems",
    "url": "http://arxiv.org/abs/2512.23708v1",
    "abstract_en": "We identify quantum geometric bounds for observables in non-Hermitian systems. We find unique bounds on non-Hermitian quantum geometric tensors, generalized two-point response correlators, conductivity tensors, and optical weights. We showcase these findings in topological systems with non-Hermitian Chern numbers. We demonstrate that the non-Hermitian geometric constraints on response functions naturally arise in open quantum systems governed by out-of-equilibrium Lindbladian dynamics. Our findings are relevant to experimental observables and responses under the realistic setups that fall beyond the idealized closed-system descriptions.",
    "date": "2025-12-29",
    "summary_cn": "本文在非厄米量子力学框架下，识别了可观测量的量子几何下界，发现其对量子几何张量、两点响应函数、电导率张量及光权重等物理量均构成限制。研究以具有非厄米陈数的拓扑系统为例进行了展示，并指出这些几何约束自然地产生于由Lindblad主方程描述的非平衡开放量子系统动力学中。这些发现对于理解真实实验条件下（非理想封闭系统）的响应函数与可观测结果具有重要意义。",
    "one_sentence": "本文在非厄米系统中为可观测量推导出普适的量子几何下界，并阐明其在非平衡开放量子系统中的物理起源。"
  },
  {
    "title": "Training AI Co-Scientists Using Rubric Rewards",
    "url": "http://arxiv.org/abs/2512.23707v1",
    "abstract_en": "AI co-scientists are emerging as a tool to assist human researchers in achieving their research goals. A crucial feature of these AI co-scientists is the ability to generate a research plan given a set of aims and constraints. The plan may be used by researchers for brainstorming, or may even be implemented after further refinement. However, language models currently struggle to generate research plans that follow all constraints and implicit requirements. In this work, we study how to leverage the vast corpus of existing research papers to train language models that generate better research plans. We build a scalable, diverse training corpus by automatically extracting research goals and goal-specific grading rubrics from papers across several domains. We then train models for research plan generation via reinforcement learning with self-grading. A frozen copy of the initial policy acts as the grader during training, with the rubrics creating a generator-verifier gap that enables improvements without external human supervision. To validate this approach, we conduct a study with human experts for machine learning research goals, spanning 225 hours. The experts prefer plans generated by our finetuned Qwen3-30B-A3B model over the initial model for 70% of research goals, and approve 84% of the automatically extracted goal-specific grading rubrics. To assess generality, we also extend our approach to research goals from medical papers, and new arXiv preprints, evaluating with a jury of frontier models. Our finetuning yields 12-22% relative improvements and significant cross-domain generalization, proving effective even in problem settings like medical research where execution feedback is infeasible. Together, these findings demonstrate the potential of a scalable, automated training recipe as a step towards improving general AI co-scientists.",
    "date": "2025-12-29",
    "summary_cn": "AI 接口暂时不可用，请阅读下方英文摘要。",
    "one_sentence": "生成失败"
  },
  {
    "title": "Non-Invertible Interfaces Between Symmetry-Enriched Critical Phases",
    "url": "http://arxiv.org/abs/2512.23706v1",
    "abstract_en": "Gapless quantum phases can become distinct when internal symmetries are enforced, in analogy with gapped symmetry-protected topological (SPT) phases. However, this distinction does not always lead to protected edge modes, raising the question of how the bulk-boundary correspondence is generalized to gapless cases. We propose that the spatial interface between gapless phases -- rather than their boundaries -- provides a more robust fingerprint. We show that whenever two 1+1d conformal field theories (CFTs) differ in symmetry charge assignments of local operators or twisted sectors, any symmetry-preserving spatial interface between the theories must flow to a non-invertible defect. We illustrate this general result for different versions of the Ising CFT with $\\mathbb{Z}_2 \\times \\mathbb{Z}_2^T$ symmetry, obtaining a complete classification of allowed conformal interfaces. When the Ising CFTs differ by nonlocal operator charges, the interface hosts 0+1d symmetry-breaking phases with finite-size splittings scaling as $1/L^3$, as well as continuous phase transitions between them. For general gapless phases differing by an SPT entangler, the interfaces between them can be mapped to conformal defects with a certain defect 't Hooft anomaly. This classification also gives implications for higher-dimensional examples, including symmetry-enriched variants of the 2+1d Ising CFT. Our results establish a physical indicator for symmetry-enriched criticality through symmetry-protected interfaces, giving a new handle on the interplay between topology and gapless phases.",
    "date": "2025-12-29",
    "summary_cn": "AI 接口暂时不可用，请阅读下方英文摘要。",
    "one_sentence": "生成失败"
  },
  {
    "title": "Diffusion Knows Transparency: Repurposing Video Diffusion for Transparent Object Depth and Normal Estimation",
    "url": "http://arxiv.org/abs/2512.23705v1",
    "abstract_en": "Transparent objects remain notoriously hard for perception systems: refraction, reflection and transmission break the assumptions behind stereo, ToF and purely discriminative monocular depth, causing holes and temporally unstable estimates. Our key observation is that modern video diffusion models already synthesize convincing transparent phenomena, suggesting they have internalized the optical rules. We build TransPhy3D, a synthetic video corpus of transparent/reflective scenes: 11k sequences rendered with Blender/Cycles. Scenes are assembled from a curated bank of category-rich static assets and shape-rich procedural assets paired with glass/plastic/metal materials. We render RGB + depth + normals with physically based ray tracing and OptiX denoising. Starting from a large video diffusion model, we learn a video-to-video translator for depth (and normals) via lightweight LoRA adapters. During training we concatenate RGB and (noisy) depth latents in the DiT backbone and co-train on TransPhy3D and existing frame-wise synthetic datasets, yielding temporally consistent predictions for arbitrary-length input videos. The resulting model, DKT, achieves zero-shot SOTA on real and synthetic video benchmarks involving transparency: ClearPose, DREDS (CatKnown/CatNovel), and TransPhy3D-Test. It improves accuracy and temporal consistency over strong image/video baselines, and a normal variant sets the best video normal estimation results on ClearPose. A compact 1.3B version runs at ~0.17 s/frame. Integrated into a grasping stack, DKT's depth boosts success rates across translucent, reflective and diffuse surfaces, outperforming prior estimators. Together, these results support a broader claim: \"Diffusion knows transparency.\" Generative video priors can be repurposed, efficiently and label-free, into robust, temporally coherent perception for challenging real-world manipulation.",
    "date": "2025-12-29",
    "summary_cn": "AI 接口暂时不可用，请阅读下方英文摘要。",
    "one_sentence": "生成失败"
  }
]