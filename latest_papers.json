[
  {
    "title": "$\\texttt{GPUmonty}$: A GPU-accelerated relativistic Monte Carlo radiative transfer code",
    "url": "http://arxiv.org/abs/2602.13198v1",
    "abstract_en": "We introduce $\\texttt{GPUmonty}$, a CUDA/C-based Monte Carlo radiative transfer code accelerated using graphics processing units (GPUs). $\\texttt{GPUmonty}$ derives from the CPU-based code $\\texttt{grmonty}$ and offloads the most computationally expensive stages of the calculation -- superphoton generation, sampling, tracking, and scattering -- to the GPU. Whereas $\\texttt{grmonty}$ handles photons sequentially, $\\texttt{GPUmonty}$ processes large numbers of superphotons concurrently, leveraging the single-instruction, multiple-thread (SIMT) execution model of modern GPUs. Benchmarks demonstrate a speedup of about $12\\times$ relative to the original CPU implementation on a single GPU, with runtime limited primarily by register pressure rather than compute or memory bandwidth saturation. We validate the implementation through analytic tests for a optically thin synchrotron sphere, as well as comparisons with $\\texttt{igrmonty}$ for scattering synchrotron sphere and GRMHD simulation data. Relative errors remain below a percent level and convergence is consistent with the expected $N_{\\rm s}^{-1/2}$ Monte Carlo scaling. By significantly reducing computational costs, GPUmonty enables the extensive parameter space surveys and faster spectra modeling required to interpret horizon-scale observations of supermassive black holes. $\\texttt{GPUmonty}$ is publicly available under the GNU General Public License.",
    "date": "2026-02-13",
    "summary_cn": "本文介绍了GPUmonty，一种利用GPU加速的CUDA/C蒙特卡洛辐射传输代码。该代码源自CPU版本的grmonty，将计算密集型任务卸载至GPU并行处理，实现了约12倍的加速。通过解析测试和对比验证，结果误差低于1%，收敛性符合预期。GPUmonty显著降低了计算成本，适用于超大质量黑洞观测的大规模参数空间调查和光谱建模。",
    "one_sentence": "本文提出了GPUmonty，一种基于CUDA/C的GPU加速蒙特卡洛辐射传输代码，通过并行处理大幅提升了计算效率。"
  },
  {
    "title": "Imitating What Works: Simulation-Filtered Modular Policy Learning from Human Videos",
    "url": "http://arxiv.org/abs/2602.13197v1",
    "abstract_en": "The ability to learn manipulation skills by watching videos of humans has the potential to unlock a new source of highly scalable data for robot learning. Here, we tackle prehensile manipulation, in which tasks involve grasping an object before performing various post-grasp motions. Human videos offer strong signals for learning the post-grasp motions, but they are less useful for learning the prerequisite grasping behaviors, especially for robots without human-like hands. A promising way forward is to use a modular policy design, leveraging a dedicated grasp generator to produce stable grasps. However, arbitrary stable grasps are often not task-compatible, hindering the robot's ability to perform the desired downstream motion. To address this challenge, we present Perceive-Simulate-Imitate (PSI), a framework for training a modular manipulation policy using human video motion data processed by paired grasp-trajectory filtering in simulation. This simulation step extends the trajectory data with grasp suitability labels, which allows for supervised learning of task-oriented grasping capabilities. We show through real-world experiments that our framework can be used to learn precise manipulation skills efficiently without any robot data, resulting in significantly more robust performance than using a grasp generator naively.",
    "date": "2026-02-13",
    "summary_cn": "本文提出了PSI框架，旨在利用人类视频教导机器人操作技能。针对非人手机器人难以从视频中学习抓取且通用抓取往往不匹配后续任务的问题，该框架通过仿真中的抓取轨迹过滤，为数据标注抓取适用性。这种方法实现了无需机器人数据的任务导向抓取学习，显著提升了实际操作的成功率与鲁棒性。",
    "one_sentence": "本文提出了PSI框架，通过在仿真中利用成对抓取轨迹过滤处理的人类视频运动数据，训练模块化操作策略，解决了非人手机器人在学习中任务导向抓取的兼容性问题。"
  },
  {
    "title": "Gravitational Background of Alice-Vortices and R7-Branes",
    "url": "http://arxiv.org/abs/2602.13196v1",
    "abstract_en": "Codimension-two vortex solutions are important solitonic objects in both quantum field theory and gravity. In this paper, we construct a class of codimension-two Alice-vortex solutions in axio-dilaton gravity, in which monodromy around the vortex enacts the axion transformation $C_0 \\mapsto -C_0$. In IIB supergravity, this furnishes a class of R7-brane backgrounds of the sort predicted by the Swampland Cobordism Conjecture. Such configurations generically carry an intrinsic dipole moment. We extract additional properties of such branes from scattering probes. These results provide further evidence that the worldvolume theory of an R7-brane is an 8D non-supersymmetric interacting quantum field theory.",
    "date": "2026-02-13",
    "summary_cn": "本文在轴子-伸缩子引力理论中构造了一类余维二爱丽丝涡旋解，其围绕涡旋的单值变换作用于轴子场。这些解在IIB超引力中对应于沼泽界限配边猜想所预测的R7膜背景，通常具有内禀偶极矩。研究通过散射探针提取了膜的性质，结果进一步支持了R7膜世界体积理论是八维非超对称相互作用量子场论的论断。",
    "one_sentence": "本文在轴子-伸缩子引力理论中构造了一类实现轴子变换的余维二爱丽丝涡旋解，为沼泽界限配边猜想提供了R7膜背景证据。"
  },
  {
    "title": "Conversational Image Segmentation: Grounding Abstract Concepts with Scalable Supervision",
    "url": "http://arxiv.org/abs/2602.13195v1",
    "abstract_en": "Conversational image segmentation grounds abstract, intent-driven concepts into pixel-accurate masks. Prior work on referring image grounding focuses on categorical and spatial queries (e.g., \"left-most apple\") and overlooks functional and physical reasoning (e.g., \"where can I safely store the knife?\"). We address this gap and introduce Conversational Image Segmentation (CIS) and ConverSeg, a benchmark spanning entities, spatial relations, intent, affordances, functions, safety, and physical reasoning. We also present ConverSeg-Net, which fuses strong segmentation priors with language understanding, and an AI-powered data engine that generates prompt-mask pairs without human supervision. We show that current language-guided segmentation models are inadequate for CIS, while ConverSeg-Net trained on our data engine achieves significant gains on ConverSeg and maintains strong performance on existing language-guided segmentation benchmarks. Project webpage: https://glab-caltech.github.io/converseg/",
    "date": "2026-02-13",
    "summary_cn": "本文聚焦于对话式图像分割，旨在解决现有方法在功能与物理推理方面的不足。作者构建了包含意图、功能性等丰富语义的ConverSeg基准，并提出了融合分割先验与语言理解的ConverSeg-Net模型。配合无需人工监督的数据引擎，该模型在处理复杂推理指令时表现出显著优势。",
    "one_sentence": "本文提出了对话式图像分割任务CIS，构建了涵盖功能推理的ConverSeg基准，并提出了融合语言理解与分割先验的ConverSeg-Net模型。"
  },
  {
    "title": "Semantic Chunking and the Entropy of Natural Language",
    "url": "http://arxiv.org/abs/2602.13194v1",
    "abstract_en": "The entropy rate of printed English is famously estimated to be about one bit per character, a benchmark that modern large language models (LLMs) have only recently approached. This entropy rate implies that English contains nearly 80 percent redundancy relative to the five bits per character expected for random text. We introduce a statistical model that attempts to capture the intricate multi-scale structure of natural language, providing a first-principles account of this redundancy level. Our model describes a procedure of self-similarly segmenting text into semantically coherent chunks down to the single-word level. The semantic structure of the text can then be hierarchically decomposed, allowing for analytical treatment. Numerical experiments with modern LLMs and open datasets suggest that our model quantitatively captures the structure of real texts at different levels of the semantic hierarchy. The entropy rate predicted by our model agrees with the estimated entropy rate of printed English. Moreover, our theory further reveals that the entropy rate of natural language is not fixed but should increase systematically with the semantic complexity of corpora, which are captured by the only free parameter in our model.",
    "date": "2026-02-13",
    "summary_cn": "本文提出了一种新的统计模型，通过自相似地分割文本并层级分解语义结构，成功解释了英语文本约80%的冗余度。数值实验表明，该模型不仅预测的熵率与实际英语相符，还揭示了语言熵率随语料库语义复杂性增加而系统增长的规律。",
    "one_sentence": "本文提出了一种统计模型，通过自相似地分割文本并层级分解语义结构，从第一性原理出发解释了英语的冗余度及其熵率。"
  }
]