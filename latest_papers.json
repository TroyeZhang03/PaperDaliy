[
  {
    "title": "Neu-PiG: Neural Preconditioned Grids for Fast Dynamic Surface Reconstruction on Long Sequences",
    "url": "http://arxiv.org/abs/2602.22212v1",
    "abstract_en": "Temporally consistent surface reconstruction of dynamic 3D objects from unstructured point cloud data remains challenging, especially for very long sequences. Existing methods either optimize deformations incrementally, risking drift and requiring long runtimes, or rely on complex learned models that demand category-specific training. We present Neu-PiG, a fast deformation optimization method based on a novel preconditioned latent-grid encoding that distributes spatial features parameterized on the position and normal direction of a keyframe surface. Our method encodes entire deformations across all time steps at various spatial scales into a multi-resolution latent grid, parameterized by the position and normal direction of a reference surface from a single keyframe. This latent representation is then augmented for time modulation and decoded into per-frame 6-DoF deformations via a lightweight multilayer perceptron (MLP). To achieve high-fidelity, drift-free surface reconstructions in seconds, we employ Sobolev preconditioning during gradient-based training of the latent space, completely avoiding the need for any explicit correspondences or further priors. Experiments across diverse human and animal datasets demonstrate that Neu-PiG outperforms state-the-art approaches, offering both superior accuracy and scalability to long sequences while running at least 60x faster than existing training-free methods and achieving inference speeds on the same order as heavy pretrained models.",
    "date": "2026-02-25",
    "summary_cn": "针对动态 3D 重建中的漂移与效率难题，本文提出 Neu-PiG 方法。该方法利用预条件潜在网格编码，将多尺度形变映射至单关键帧表面，结合 Sobolev 预条件技术，在无需对应关系或特定训练的情况下，实现秒级高精度、无漂移的重建，显著优于现有方法。",
    "one_sentence": "本文提出了一种基于新颖预条件潜在网格编码的 Neu-PiG 方法，通过将多分辨率时空形变特征参数化到单关键帧表面，实现了无漂移、高保真且极快的动态 3D 物体重建。"
  },
  {
    "title": "Computing with many encoded logical qubits beyond break-even",
    "url": "http://arxiv.org/abs/2602.22211v1",
    "abstract_en": "High-rate quantum error correcting (QEC) codes encode many logical qubits in a given number of physical qubits, making them promising candidates for quantum computation. Implementing high-rate codes at a scale that both frustrates classical computing and improves performance by encoding requires both high fidelity gates and long-range qubit connectivity -- both of which are offered by trapped-ion quantum computers. Here, we demonstrate computations that outperform their unencoded counterparts in the high-rate $[[ k+2,\\, k,\\, 2 ]]$ iceberg quantum error detecting (QED) and $[[ (k_2 + 2)(k_1 + 2),\\, k_2k_1,\\, 4 ]]$ two-level concatenated iceberg QEC codes, using the 98-qubit Quantinuum Helios trapped-ion quantum processor. Utilizing new gadgets for encoded operations, we realize this \"beyond break-even\" performance with reasonable postselection rates across a range of fault-tolerant (FT) and partially-fault-tolerant (pFT) component and application benchmarks with between $48$ and $94$ logical qubits. These benchmarks include FT state preparation and measurement, QEC cycle benchmarking, logical gate benchmarking, GHZ state preparation, and a pFT quantum simulation of the three-dimensional $XY$ model of quantum magnetism. Additionally, we illustrate that postselection rates can be suppressed by increasing the code distance via concatenation. Our results represent state-of-the-art logical component and state fidelities and provide evidence that high-rate QED/QEC codes are viable on contemporary quantum computers for near-term beyond-classical-scale computation.",
    "date": "2026-02-25",
    "summary_cn": "本文利用 Quantinuum Helios 离子阱量子处理器，演示了高码率 Iceberg 量子纠错与检错码的计算优势。通过新型编码操作工具，研究在多项基准测试中实现了超越未编码性能的表现，并证明通过级联增加码距可降低后选择率，为近期超经典规模计算提供了可行路径。",
    "one_sentence": "本文在 98 量子比特的 Quantinuum Helios 离子阱处理器上，利用新型编码操作工具实现了高码率 Iceberg 量子纠错码，首次在多种基准测试中展现出超越未编码性能的“盈亏平衡”突破。"
  },
  {
    "title": "WHOLE: World-Grounded Hand-Object Lifted from Egocentric Videos",
    "url": "http://arxiv.org/abs/2602.22209v1",
    "abstract_en": "Egocentric manipulation videos are highly challenging due to severe occlusions during interactions and frequent object entries and exits from the camera view as the person moves. Current methods typically focus on recovering either hand or object pose in isolation, but both struggle during interactions and fail to handle out-of-sight cases. Moreover, their independent predictions often lead to inconsistent hand-object relations. We introduce WHOLE, a method that holistically reconstructs hand and object motion in world space from egocentric videos given object templates. Our key insight is to learn a generative prior over hand-object motion to jointly reason about their interactions. At test time, the pretrained prior is guided to generate trajectories that conform to the video observations. This joint generative reconstruction substantially outperforms approaches that process hands and objects separately followed by post-processing. WHOLE achieves state-of-the-art performance on hand motion estimation, 6D object pose estimation, and their relative interaction reconstruction. Project website: https://judyye.github.io/whole-www",
    "date": "2026-02-25",
    "summary_cn": "针对第一人称操作视频中严重的遮挡和物体进出视野问题，本文提出 WHOLE 方法。该方法利用学习到的手 - 物运动生成先验，联合推理交互过程，在世界空间中整体重建手部与物体运动。实验表明，其在手部运动、6D 物体姿态及交互重建任务上均达到最先进水平。",
    "one_sentence": "本文提出了 WHOLE 方法，通过学习手 - 物运动的生成先验，在给定物体模板的情况下，从第一人称视频中联合推理并重建世界空间中的手部和物体运动。"
  },
  {
    "title": "Solaris: Building a Multiplayer Video World Model in Minecraft",
    "url": "http://arxiv.org/abs/2602.22208v1",
    "abstract_en": "Existing action-conditioned video generation models (video world models) are limited to single-agent perspectives, failing to capture the multi-agent interactions of real-world environments. We introduce Solaris, a multiplayer video world model that simulates consistent multi-view observations. To enable this, we develop a multiplayer data system designed for robust, continuous, and automated data collection on video games such as Minecraft. Unlike prior platforms built for single-player settings, our system supports coordinated multi-agent interaction and synchronized videos + actions capture. Using this system, we collect 12.64 million multiplayer frames and propose an evaluation framework for multiplayer movement, memory, grounding, building, and view consistency. We train Solaris using a staged pipeline that progressively transitions from single-player to multiplayer modeling, combining bidirectional, causal, and Self Forcing training. In the final stage, we introduce Checkpointed Self Forcing, a memory-efficient Self Forcing variant that enables a longer-horizon teacher. Results show our architecture and training design outperform existing baselines. Through open-sourcing our system and models, we hope to lay the groundwork for a new generation of multi-agent world models.",
    "date": "2026-02-25",
    "summary_cn": "针对现有视频世界模型局限于单智能体视角的问题，本文提出 Solaris 多玩家模型。通过构建支持协同交互的数据系统采集千万级帧数据，并采用从单人到多人的分阶段训练及检查点自强化技术，实现了多视图一致性与多智能体交互模拟，性能优于现有基准。",
    "one_sentence": "本文提出了 Solaris，一种结合专为鲁棒多智能体数据采集设计的系统、分阶段训练策略及新型显存优化自强化机制的多玩家视频世界模型。"
  },
  {
    "title": "Recovered in Translation: Efficient Pipeline for Automated Translation of Benchmarks and Datasets",
    "url": "http://arxiv.org/abs/2602.22207v1",
    "abstract_en": "The reliability of multilingual Large Language Model (LLM) evaluation is currently compromised by the inconsistent quality of translated benchmarks. Existing resources often suffer from semantic drift and context loss, which can lead to misleading performance metrics. In this work, we present a fully automated framework designed to address these challenges by enabling scalable, high-quality translation of datasets and benchmarks. We demonstrate that adapting test-time compute scaling strategies, specifically Universal Self-Improvement (USI) and our proposed multi-round ranking method, T-RANK, allows for significantly higher quality outputs compared to traditional pipelines. Our framework ensures that benchmarks preserve their original task structure and linguistic nuances during localization. We apply this approach to translate popular benchmarks and datasets into eight Eastern and Southern European languages (Ukrainian, Bulgarian, Slovak, Romanian, Lithuanian, Estonian, Turkish, Greek). Evaluations using both reference-based metrics and LLM-as-a-judge show that our translations surpass existing resources, resulting in more accurate downstream model assessment. We release both the framework and the improved benchmarks to facilitate robust and reproducible multilingual AI development.",
    "date": "2026-02-25",
    "summary_cn": "针对多语言大模型评估中翻译质量不一致的问题，本文提出全自动化框架，利用测试时计算扩展策略及新提出的 T-RANK 方法，显著提升了数据集翻译的语义准确性。该方法成功将主流基准本地化为八种东欧及南欧语言，确保了任务结构与语言细微差别的保留，为鲁棒的多语言 AI 开发提供了优质资源。",
    "one_sentence": "本文提出了一种全自动化框架，通过适配测试时计算扩展策略（USI）及新提出的多轮排序方法（T-RANK），实现了高质量、可扩展的多语言基准数据集翻译。"
  }
]