[
  {
    "title": "One Hand to Rule Them All: Canonical Representations for Unified Dexterous Manipulation",
    "url": "http://arxiv.org/abs/2602.16712v1",
    "abstract_en": "Dexterous manipulation policies today largely assume fixed hand designs, severely restricting their generalization to new embodiments with varied kinematic and structural layouts. To overcome this limitation, we introduce a parameterized canonical representation that unifies a broad spectrum of dexterous hand architectures. It comprises a unified parameter space and a canonical URDF format, offering three key advantages. 1) The parameter space captures essential morphological and kinematic variations for effective conditioning in learning algorithms. 2) A structured latent manifold can be learned over our space, where interpolations between embodiments yield smooth and physically meaningful morphology transitions. 3) The canonical URDF standardizes the action space while preserving dynamic and functional properties of the original URDFs, enabling efficient and reliable cross-embodiment policy learning. We validate these advantages through extensive analysis and experiments, including grasp policy replay, VAE latent encoding, and cross-embodiment zero-shot transfer. Specifically, we train a VAE on the unified representation to obtain a compact, semantically rich latent embedding, and develop a grasping policy conditioned on the canonical representation that generalizes across dexterous hands. We demonstrate, through simulation and real-world tasks on unseen morphologies (e.g., 81.9% zero-shot success rate on 3-finger LEAP Hand), that our framework unifies both the representational and action spaces of structurally diverse hands, providing a scalable foundation for cross-hand learning toward universal dexterous manipulation.",
    "date": "2026-02-18",
    "summary_cn": "针对灵巧操作策略泛化能力受限的问题，本文提出了一种参数化规范表示法。该方法包含统一的参数空间和规范URDF格式，能够捕捉形态和运动学变化，并支持跨本体策略学习。实验证明，该方法在未见过的形态上实现了高效的零样本迁移，为通用灵巧操作提供了可扩展的基础。",
    "one_sentence": "本文提出了一种参数化规范表示法，通过统一参数空间和规范URDF格式，实现了对不同灵巧手架构的统一表示和跨本体策略学习。"
  },
  {
    "title": "TeCoNeRV: Leveraging Temporal Coherence for Compressible Neural Representations for Videos",
    "url": "http://arxiv.org/abs/2602.16711v1",
    "abstract_en": "Implicit Neural Representations (INRs) have recently demonstrated impressive performance for video compression. However, since a separate INR must be overfit for each video, scaling to high-resolution videos while maintaining encoding efficiency remains a significant challenge. Hypernetwork-based approaches predict INR weights (hyponetworks) for unseen videos at high speeds, but with low quality, large compressed size, and prohibitive memory needs at higher resolutions. We address these fundamental limitations through three key contributions: (1) an approach that decomposes the weight prediction task spatially and temporally, by breaking short video segments into patch tubelets, to reduce the pretraining memory overhead by 20$\\times$; (2) a residual-based storage scheme that captures only differences between consecutive segment representations, significantly reducing bitstream size; and (3) a temporal coherence regularization framework that encourages changes in the weight space to be correlated with video content. Our proposed method, TeCoNeRV, achieves substantial improvements of 2.47dB and 5.35dB PSNR over the baseline at 480p and 720p on UVG, with 36% lower bitrates and 1.5-3$\\times$ faster encoding speeds. With our low memory usage, we are the first hypernetwork approach to demonstrate results at 480p, 720p and 1080p on UVG, HEVC and MCL-JCV. Our project page is available at https://namithap10.github.io/teconerv/ .",
    "date": "2026-02-18",
    "summary_cn": "本文提出了一种名为TeCoNeRV的隐式神经表示方法，通过时空分解、残差存储和时间一致性正则化，显著提升了视频压缩的质量和效率。该方法在480p、720p和1080p分辨率下实现了更高的PSNR和更低的比特率，同时大幅降低了内存开销，首次支持高分辨率视频的高效压缩。",
    "one_sentence": "本文提出了一种基于时空分解和残差存储的隐式神经表示方法，显著提升了视频压缩的质量、效率和分辨率支持。"
  },
  {
    "title": "EgoScale: Scaling Dexterous Manipulation with Diverse Egocentric Human Data",
    "url": "http://arxiv.org/abs/2602.16710v1",
    "abstract_en": "Human behavior is among the most scalable sources of data for learning physical intelligence, yet how to effectively leverage it for dexterous manipulation remains unclear. While prior work demonstrates human to robot transfer in constrained settings, it is unclear whether large scale human data can support fine grained, high degree of freedom dexterous manipulation. We present EgoScale, a human to dexterous manipulation transfer framework built on large scale egocentric human data. We train a Vision Language Action (VLA) model on over 20,854 hours of action labeled egocentric human video, more than 20 times larger than prior efforts, and uncover a log linear scaling law between human data scale and validation loss. This validation loss strongly correlates with downstream real robot performance, establishing large scale human data as a predictable supervision source. Beyond scale, we introduce a simple two stage transfer recipe: large scale human pretraining followed by lightweight aligned human robot mid training. This enables strong long horizon dexterous manipulation and one shot task adaptation with minimal robot supervision. Our final policy improves average success rate by 54% over a no pretraining baseline using a 22 DoF dexterous robotic hand, and transfers effectively to robots with lower DoF hands, indicating that large scale human motion provides a reusable, embodiment agnostic motor prior.",
    "date": "2026-02-18",
    "summary_cn": "本文提出EgoScale框架，利用超过2万小时的第一人称人类视频训练视觉-语言-动作模型。研究发现人类数据规模与验证损失呈对数线性关系，且验证损失能预测实际机器人性能。通过大规模人类预训练和轻量级人机对齐的两阶段方法，在22自由度灵巧手上实现54%成功率提升，证明了大规模人类数据作为可预测监督源的有效性。",
    "one_sentence": "本文提出基于大规模第一人称人类视频的EgoScale框架，揭示了人类数据规模与性能的对数线性关系，并通过两阶段迁移方法实现了灵巧操作任务的显著提升。"
  },
  {
    "title": "Knowledge-Embedded Latent Projection for Robust Representation Learning",
    "url": "http://arxiv.org/abs/2602.16709v1",
    "abstract_en": "Latent space models are widely used for analyzing high-dimensional discrete data matrices, such as patient-feature matrices in electronic health records (EHRs), by capturing complex dependence structures through low-dimensional embeddings. However, estimation becomes challenging in the imbalanced regime, where one matrix dimension is much larger than the other. In EHR applications, cohort sizes are often limited by disease prevalence or data availability, whereas the feature space remains extremely large due to the breadth of medical coding system. Motivated by the increasing availability of external semantic embeddings, such as pre-trained embeddings of clinical concepts in EHRs, we propose a knowledge-embedded latent projection model that leverages semantic side information to regularize representation learning. Specifically, we model column embeddings as smooth functions of semantic embeddings via a mapping in a reproducing kernel Hilbert space. We develop a computationally efficient two-step estimation procedure that combines semantically guided subspace construction via kernel principal component analysis with scalable projected gradient descent. We establish estimation error bounds that characterize the trade-off between statistical error and approximation error induced by the kernel projection. Furthermore, we provide local convergence guarantees for our non-convex optimization procedure. Extensive simulation studies and a real-world EHR application demonstrate the effectiveness of the proposed method.",
    "date": "2026-02-18",
    "summary_cn": "针对电子健康记录等高维离散数据中存在的维度不平衡问题，本文提出了一种知识嵌入潜在投影模型。该模型利用外部语义嵌入作为辅助信息，通过核希尔伯特空间映射正则化表示学习，并设计了高效的两步估计算法。理论分析证明了估计误差界限及局部收敛性，实验验证了该方法的有效性。",
    "one_sentence": "本文提出了一种知识嵌入潜在投影模型，利用外部语义嵌入作为辅助信息，有效解决了高维非平衡数据矩阵估计中的挑战。"
  },
  {
    "title": "Policy Compiler for Secure Agentic Systems",
    "url": "http://arxiv.org/abs/2602.16708v1",
    "abstract_en": "LLM-based agents are increasingly being deployed in contexts requiring complex authorization policies: customer service protocols, approval workflows, data access restrictions, and regulatory compliance. Embedding these policies in prompts provides no enforcement guarantees. We present PCAS, a Policy Compiler for Agentic Systems that provides deterministic policy enforcement.   Enforcing such policies requires tracking information flow across agents, which linear message histories cannot capture. Instead, PCAS models the agentic system state as a dependency graph capturing causal relationships among events such as tool calls, tool results, and messages. Policies are expressed in a Datalog-derived language, as declarative rules that account for transitive information flow and cross-agent provenance. A reference monitor intercepts all actions and blocks violations before execution, providing deterministic enforcement independent of model reasoning.   PCAS takes an existing agent implementation and a policy specification, and compiles them into an instrumented system that is policy-compliant by construction, with no security-specific restructuring required. We evaluate PCAS on three case studies: information flow policies for prompt injection defense, approval workflows in a multi-agent pharmacovigilance system, and organizational policies for customer service. On customer service tasks, PCAS improves policy compliance from 48% to 93% across frontier models, with zero policy violations in instrumented runs.",
    "date": "2026-02-18",
    "summary_cn": "针对LLM智能体在复杂授权策略执行上的不足，本文提出了PCAS系统。它通过依赖图追踪跨智能体的信息流，利用Datalog衍生语言声明策略，并在执行前拦截违规行为，从而提供确定性的策略强制执行。实验表明，PCAS能显著提升策略合规率并杜绝违规。",
    "one_sentence": "本文提出了一种策略编译器PCAS，通过构建依赖图追踪信息流并利用引用监视器，实现了对LLM智能体系统策略的确定性强制执行。"
  }
]