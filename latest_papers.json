[
  {
    "title": "UniX: Unifying Autoregression and Diffusion for Chest X-Ray Understanding and Generation",
    "url": "http://arxiv.org/abs/2601.11522v1",
    "abstract_en": "Despite recent progress, medical foundation models still struggle to unify visual understanding and generation, as these tasks have inherently conflicting goals: semantic abstraction versus pixel-level reconstruction. Existing approaches, typically based on parameter-shared autoregressive architectures, frequently lead to compromised performance in one or both tasks. To address this, we present UniX, a next-generation unified medical foundation model for chest X-ray understanding and generation. UniX decouples the two tasks into an autoregressive branch for understanding and a diffusion branch for high-fidelity generation. Crucially, a cross-modal self-attention mechanism is introduced to dynamically guide the generation process with understanding features. Coupled with a rigorous data cleaning pipeline and a multi-stage training strategy, this architecture enables synergistic collaboration between tasks while leveraging the strengths of diffusion models for superior generation. On two representative benchmarks, UniX achieves a 46.1% improvement in understanding performance (Micro-F1) and a 24.2% gain in generation quality (FD-RadDino), using only a quarter of the parameters of LLM-CXR. By achieving performance on par with task-specific models, our work establishes a scalable paradigm for synergistic medical image understanding and generation. Codes and models are available at https://github.com/ZrH42/UniX.",
    "date": "2026-01-16",
    "summary_cn": "AI 接口暂时不可用，请阅读下方英文摘要。",
    "one_sentence": "生成失败"
  },
  {
    "title": "X-ray Polarization of the Intrabinary Shock in Redback Pulsar J1723$-$2837",
    "url": "http://arxiv.org/abs/2601.11521v1",
    "abstract_en": "The intrabinary shocks (IBS) in spider pulsars emit non-thermal synchrotron X-rays from accelerated electrons and positrons in the shocked pulsar wind, likely energized by magnetic reconnection. The double-peaked X-ray light curves from these shocks have been well characterized in several spider systems. In this paper, we analyze Imaging X-ray Polarimetry Explorer (IXPE) observations of the redback pulsar J1723$-$2837 to examine the expected synchrotron polarization. Using advanced extraction methods that include spatial, temporal, and particle background weights, we constrain the polarization of the IBS. We compare different models for the magnetic field in the radiation zone and find that the best fit prefers a striped pulsar wind model over other polarized models, with maximum polarization degree of the IBS emission component $Π_{\\rm IBS}=36^{+16}_{-15}\\%$, in addition to an unpolarized non-IBS component. Since this is only 2.4$σ$, we cannot claim strong preference over an unpolarized model; we report a $99\\%$ confidence level upper limit on the total polarization of both IBS and non-IBS components $Π_{99}<36\\%$, which is improved over the $50\\%$ limit obtained in previous work. The best-fit polarization of the IBS component is consistent with numerical simulations. Detailed tests of such models are accessible to future measurements.",
    "date": "2026-01-16",
    "summary_cn": "AI 接口暂时不可用，请阅读下方英文摘要。",
    "one_sentence": "生成失败"
  },
  {
    "title": "Empirical Coordination over Markov Channel with Independent Source",
    "url": "http://arxiv.org/abs/2601.11520v1",
    "abstract_en": "We study joint source-channel coding over Markov channels through the empirical coordination framework. More specifically, we aim at determining the empirical distributions of source and channel symbols that can be induced by a coding scheme. We consider strictly causal encoders that generate channel inputs, without access to the past channel states, henceforth driving the current Markov state evolution. Our main result is the single-letter inner and outer bounds of the set of achievable joint distributions, coordinating all the symbols in the network. To establish the inner bound, we introduce a new notion of typicality, the input-driven Markov typicality, and develop its fundamental properties. Contrary to the classical block-Markov coding schemes that rely on blockwise independence for discrete memoryless channels, our analysis directly exploits the Markov channel structure and improves beyond the independence-based arguments.",
    "date": "2026-01-16",
    "summary_cn": "AI 接口暂时不可用，请阅读下方英文摘要。",
    "one_sentence": "生成失败"
  },
  {
    "title": "How Long Is a Piece of String? A Brief Empirical Analysis of Tokenizers",
    "url": "http://arxiv.org/abs/2601.11518v1",
    "abstract_en": "Frontier LLMs are increasingly utilised across academia, society and industry. A commonly used unit for comparing models, their inputs and outputs, and estimating inference pricing is the token. In general, tokens are used as a stable currency, assumed to be broadly consistent across tokenizers and contexts, enabling direct comparisons. However, tokenization varies significantly across models and domains of text, making naive interpretation of token counts problematic. We quantify this variation by providing a comprehensive empirical analysis of tokenization, exploring the compression of sequences to tokens across different distributions of textual data. Our analysis challenges commonly held heuristics about token lengths, finding them to be overly simplistic. We hope the insights of our study add clarity and intuition toward tokenization in contemporary LLMs.",
    "date": "2026-01-16",
    "summary_cn": "AI 接口暂时不可用，请阅读下方英文摘要。",
    "one_sentence": "生成失败"
  },
  {
    "title": "Do explanations generalize across large reasoning models?",
    "url": "http://arxiv.org/abs/2601.11517v1",
    "abstract_en": "Large reasoning models (LRMs) produce a textual chain of thought (CoT) in the process of solving a problem, which serves as a potentially powerful tool to understand the problem by surfacing a human-readable, natural-language explanation. However, it is unclear whether these explanations generalize, i.e. whether they capture general patterns about the underlying problem rather than patterns which are esoteric to the LRM. This is a crucial question in understanding or discovering new concepts, e.g. in AI for science. We study this generalization question by evaluating a specific notion of generalizability: whether explanations produced by one LRM induce the same behavior when given to other LRMs. We find that CoT explanations often exhibit this form of generalization (i.e. they increase consistency between LRMs) and that this increased generalization is correlated with human preference rankings and post-training with reinforcement learning. We further analyze the conditions under which explanations yield consistent answers and propose a straightforward, sentence-level ensembling strategy that improves consistency. Taken together, these results prescribe caution when using LRM explanations to yield new insights and outline a framework for characterizing LRM explanation generalization.",
    "date": "2026-01-16",
    "summary_cn": "AI 接口暂时不可用，请阅读下方英文摘要。",
    "one_sentence": "生成失败"
  }
]