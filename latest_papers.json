[
  {
    "title": "Manifold limit for the training of shallow graph convolutional neural networks",
    "url": "http://arxiv.org/abs/2601.06025v1",
    "abstract_en": "We study the discrete-to-continuum consistency of the training of shallow graph convolutional neural networks (GCNNs) on proximity graphs of sampled point clouds under a manifold assumption. Graph convolution is defined spectrally via the graph Laplacian, whose low-frequency spectrum approximates that of the Laplace-Beltrami operator of the underlying smooth manifold, and shallow GCNNs of possibly infinite width are linear functionals on the space of measures on the parameter space. From this functional-analytic perspective, graph signals are seen as spatial discretizations of functions on the manifold, which leads to a natural notion of training data consistent across graph resolutions. To enable convergence results, the continuum parameter space is chosen as a weakly compact product of unit balls, with Sobolev regularity imposed on the output weight and bias, but not on the convolutional parameter. The corresponding discrete parameter spaces inherit the corresponding spectral decay, and are additionally restricted by a frequency cutoff adapted to the informative spectral window of the graph Laplacians. Under these assumptions, we prove $Γ$-convergence of regularized empirical risk minimization functionals and corresponding convergence of their global minimizers, in the sense of weak convergence of the parameter measures and uniform convergence of the functions over compact sets. This provides a formalization of mesh and sample independence for the training of such networks.",
    "date": "2026-01-09",
    "summary_cn": "本文研究了浅层图卷积神经网络在流形采样点云图上的训练问题。通过将图卷积与流形上的拉普拉斯-贝尔特拉米算子谱相联系，并将网络参数视为测度空间上的线性泛函，作者构建了跨图分辨率一致的训练数据概念。在特定参数空间假设下，证明了正则化经验风险泛函的Γ-收敛及其全局极小元的收敛性，从而为这类网络的网格与样本独立性训练提供了严格的数学框架。",
    "one_sentence": "本文在流形假设下，通过Γ-收敛理论，证明了浅层图卷积神经网络在采样点云邻近图上的正则化经验风险最小化具有离散到连续的收敛性，为其训练提供了网格与样本独立性的严格形式化。"
  },
  {
    "title": "AdaFuse: Adaptive Ensemble Decoding with Test-Time Scaling for LLMs",
    "url": "http://arxiv.org/abs/2601.06022v1",
    "abstract_en": "Large language models (LLMs) exhibit complementary strengths arising from differences in pretraining data, model architectures, and decoding behaviors. Inference-time ensembling provides a practical way to combine these capabilities without retraining. However, existing ensemble approaches suffer from fundamental limitations. Most rely on fixed fusion granularity, which lacks the flexibility required for mid-generation adaptation and fails to adapt to different generation characteristics across tasks. To address these challenges, we propose AdaFuse, an adaptive ensemble decoding framework that dynamically selects semantically appropriate fusion units during generation. Rather than committing to a fixed granularity, AdaFuse adjusts fusion behavior on the fly based on the decoding context, with words serving as basic building blocks for alignment. To be specific, we introduce an uncertainty-based criterion to decide whether to apply ensembling at each decoding step. Under confident decoding states, the model continues generation directly. In less certain states, AdaFuse invokes a diversity-aware scaling strategy to explore alternative candidate continuations and inform ensemble decisions. This design establishes a synergistic interaction between adaptive ensembling and test-time scaling, where ensemble decisions guide targeted exploration, and the resulting diversity in turn strengthens ensemble quality. Experiments on open-domain question answering, arithmetic reasoning, and machine translation demonstrate that AdaFuse consistently outperforms strong ensemble baselines, achieving an average relative improvement of 6.88%. The code is available at https://github.com/CCM0111/AdaFuse.",
    "date": "2026-01-09",
    "summary_cn": "针对现有大型语言模型集成方法因采用固定融合粒度而缺乏灵活性的问题，本文提出了自适应集成解码框架AdaFuse。该框架在解码过程中，基于不确定性标准动态决定是否进行集成，并在不确定时通过多样性感知的扩展策略探索候选续写，实现集成决策与扩展的协同。在多项任务上的实验表明，AdaFuse能稳定超越现有基线方法。",
    "one_sentence": "本文提出了一种名为AdaFuse的自适应集成解码框架，该框架能根据解码上下文动态选择语义合适的融合粒度，以灵活提升大型语言模型集成效果。"
  },
  {
    "title": "Chaining the Evidence: Robust Reinforcement Learning for Deep Search Agents with Citation-Aware Rubric Rewards",
    "url": "http://arxiv.org/abs/2601.06021v1",
    "abstract_en": "Reinforcement learning (RL) has emerged as a critical technique for enhancing LLM-based deep search agents. However, existing approaches primarily rely on binary outcome rewards, which fail to capture the comprehensiveness and factuality of agents' reasoning process, and often lead to undesirable behaviors such as shortcut exploitation and hallucinations. To address these limitations, we propose \\textbf{Citation-aware Rubric Rewards (CaRR)}, a fine-grained reward framework for deep search agents that emphasizes reasoning comprehensiveness, factual grounding, and evidence connectivity. CaRR decomposes complex questions into verifiable single-hop rubrics and requires agents to satisfy these rubrics by explicitly identifying hidden entities, supporting them with correct citations, and constructing complete evidence chains that link to the predicted answer. We further introduce \\textbf{Citation-aware Group Relative Policy Optimization (C-GRPO)}, which combines CaRR and outcome rewards for training robust deep search agents. Experiments show that C-GRPO consistently outperforms standard outcome-based RL baselines across multiple deep search benchmarks. Our analysis also validates that C-GRPO effectively discourages shortcut exploitation, promotes comprehensive, evidence-grounded reasoning, and exhibits strong generalization to open-ended deep research tasks. Our code and data are available at https://github.com/THUDM/CaRR.",
    "date": "2026-01-09",
    "summary_cn": "强化学习是提升基于大语言模型的深度搜索智能体的关键技术，但现有方法依赖二元结果奖励，导致推理过程不全面、事实依据不足，并引发走捷径和幻觉等问题。为解决这些局限，本文提出了细粒度奖励框架CaRR，它将复杂问题分解为可验证的单步标准，要求智能体通过识别隐藏实体、提供正确引用和构建完整证据链来满足这些标准。此外，还提出了C-GRPO优化方法，结合CaRR与结果奖励进行训练。实验表明，该方法在多个深度搜索基准测试中优于标准基线，能有效抑制走捷径行为，促进全面、基于证据的推理，并在开放性研究任务中展现出良好的泛化能力。",
    "one_sentence": "本文提出了一个强调推理全面性、事实依据和证据链连接的细粒度奖励框架（CaRR）及其配套的强化学习优化方法（C-GRPO），以解决现有基于大语言模型的深度搜索智能体在强化学习中因使用二元结果奖励而导致的走捷径和幻觉等问题。"
  },
  {
    "title": "Mobility Trajectories from Network-Driven Markov Dynamics",
    "url": "http://arxiv.org/abs/2601.06020v1",
    "abstract_en": "We present a generative model of human mobility in which trajectories arise as realizations of a prescribed, time-dependent Markov dynamics defined on a spatial interaction network. The model constructs a hierarchical routing structure with hubs, corridors, feeder paths, and metro links, and specifies transition matrices using gravity-type distance decay combined with externally imposed temporal schedules and directional biases. Population mass evolves as indistinguishable, memoryless movers performing a single transition per time step.   When aggregated, the resulting trajectories reproduce structured origin-destination flows that reflect network geometry, temporal modulation, and connectivity constraints. By applying the Perron-Frobenius theorem to the daily evolution operator, we identify a unique periodic invariant population distribution that serves as a natural non-transient reference state. We verify consistency between trajectory-level realizations and multi-step Markov dynamics, showing that discrepancies are entirely attributable to finite-population sampling. The framework provides a network-centric, privacy-preserving approach to generating mobility trajectories and studying time-elapsed flow structure without invoking individual-level behavioral assumptions.",
    "date": "2026-01-09",
    "summary_cn": "该研究提出了一种在空间交互网络上生成人口移动轨迹的模型。该模型采用具有层级结构（如枢纽、走廊）的网络，结合重力式距离衰减、时间表和方向偏好来定义时变马尔可夫转移概率。模型生成的无记忆移动者轨迹在聚合后能再现反映网络结构与时间调制的OD流。通过应用佩龙-弗罗贝尼乌斯定理，模型确定了周期不变的总体分布作为参考状态。该框架提供了一种以网络为中心、保护隐私的轨迹生成与流结构分析方法。",
    "one_sentence": "本文提出了一种基于时变马尔可夫动态与空间交互网络的生成式人口移动模型，通过佩龙-弗罗贝尼乌斯定理定义了周期不变分布作为非瞬态参考状态。"
  },
  {
    "title": "A Halász-type theorem for permutation anticoncentration",
    "url": "http://arxiv.org/abs/2601.06019v1",
    "abstract_en": "Given a set $A=\\{a_1,\\ldots,a_n\\}$ of real numbers and real coefficients $b_1,\\ldots,b_n$, consider the distribution of the sum obtained by pairing the $a_i$'s with the $b_i$'s according to a uniformly random permutation. A recent theorem of Pawlowski shows that as soon as the coefficients are not all equal, this distribution is always spread out at scale $n^{-1}$: no single value can occur with probability larger than $\\frac{1}{2\\lceil n/2\\rceil + 1}$, and this bound is sharp in general.   We show that stronger anticoncentration holds when the coefficients have additional diversity. We quantify the structure of the coefficient multiset by a simple statistic depending on its multiplicity profile, and prove that the maximum point mass of the permuted sum decays polynomially faster as this statistic grows. In particular, when the coefficients are all distinct we obtain a bound of $n^{-5/2+o(1)}$, which can be regarded as an analogue of a classical theorem of Erdős and Moser.",
    "date": "2026-01-09",
    "summary_cn": "本文研究实数集合与系数按随机排列配对后求和的分布。在Pawlowski定理证明该分布总在尺度n^{-1}上分散的基础上，本文进一步发现，当系数集合具有更强的多样性时，反集中效应会显著增强。通过引入一个依赖于系数多重集结构的简单统计量进行量化，作者证明了该分布的最大点质量（即单个值出现的最大概率）会随着该统计量的增大而以多项式速度更快地衰减。特别地，当所有系数均不相同时，得到了n^{-5/2+o(1)}的界，这可视作对Erdős和Moser经典定理的一个类比。",
    "one_sentence": "本文证明了当系数具有更多样性时，随机排列和的分布具有更强的反集中性，其最大点质量随系数多重集结构统计量的增长而多项式级衰减。"
  }
]