[
  {
    "title": "Scaling Verification Can Be More Effective than Scaling Policy Learning for Vision-Language-Action Alignment",
    "url": "http://arxiv.org/abs/2602.12281v1",
    "abstract_en": "The long-standing vision of general-purpose robots hinges on their ability to understand and act upon natural language instructions. Vision-Language-Action (VLA) models have made remarkable progress toward this goal, yet their generated actions can still misalign with the given instructions. In this paper, we investigate test-time verification as a means to shrink the \"intention-action gap.'' We first characterize the test-time scaling law for embodied instruction following and demonstrate that jointly scaling the number of rephrased instructions and generated actions greatly increases test-time sample diversity, often recovering correct actions more efficiently than scaling each dimension independently. To capitalize on these scaling laws, we present CoVer, a contrastive verifier for vision-language-action alignment, and show that our architecture scales gracefully with additional computational resources and data. We then introduce \"boot-time compute\" and a hierarchical verification inference pipeline for VLAs. At deployment, our framework precomputes a diverse set of rephrased instructions from a Vision-Language-Model (VLM), repeatedly generates action candidates for each instruction, and then uses a verifier to select the optimal high-level prompt and low-level action chunks. Compared to scaling policy pre-training on the same data, our verification approach yields 22% gains in-distribution and 13% out-of-distribution on the SIMPLER benchmark, with a further 45% improvement in real-world experiments. On the PolaRiS benchmark, CoVer achieves 14% gains in task progress and 9% in success rate.",
    "date": "2026-02-12",
    "summary_cn": "本文针对具身指令跟随中存在的“意图-动作”偏差，提出了一种名为CoVer的对比验证框架。该研究揭示了测试时的扩展规律，通过联合扩展指令重述与动作生成来增加样本多样性，并结合分层验证推理流程筛选最优动作。实验表明，相比单纯扩大预训练规模，该方法在仿真与真实环境中均显著提升了任务成功率。",
    "one_sentence": "本文提出了CoVer框架，通过引入对比验证器和分层验证推理流程，利用测试时计算扩展来弥合具身指令跟随中的“意图-动作”差距。"
  },
  {
    "title": "Stroke of Surprise: Progressive Semantic Illusions in Vector Sketching",
    "url": "http://arxiv.org/abs/2602.12280v1",
    "abstract_en": "Visual illusions traditionally rely on spatial manipulations such as multi-view consistency. In this work, we introduce Progressive Semantic Illusions, a novel vector sketching task where a single sketch undergoes a dramatic semantic transformation through the sequential addition of strokes. We present Stroke of Surprise, a generative framework that optimizes vector strokes to satisfy distinct semantic interpretations at different drawing stages. The core challenge lies in the \"dual-constraint\": initial prefix strokes must form a coherent object (e.g., a duck) while simultaneously serving as the structural foundation for a second concept (e.g., a sheep) upon adding delta strokes. To address this, we propose a sequence-aware joint optimization framework driven by a dual-branch Score Distillation Sampling (SDS) mechanism. Unlike sequential approaches that freeze the initial state, our method dynamically adjusts prefix strokes to discover a \"common structural subspace\" valid for both targets. Furthermore, we introduce a novel Overlay Loss that enforces spatial complementarity, ensuring structural integration rather than occlusion. Extensive experiments demonstrate that our method significantly outperforms state-of-the-art baselines in recognizability and illusion strength, successfully expanding visual anagrams from the spatial to the temporal dimension. Project page: https://stroke-of-surprise.github.io/",
    "date": "2026-02-12",
    "summary_cn": "本文介绍了“渐进式语义错觉”这一新型矢量素描任务，旨在通过笔画的顺序添加实现单一素描的语义转换。提出的“Stroke of Surprise”框架利用双分支分数蒸馏采样和序列感知联合优化，解决了双约束挑战，动态调整前缀笔画以发现共同结构子空间，并通过覆盖损失确保结构整合。实验证明该方法在识别性和错觉强度上显著优于现有技术。",
    "one_sentence": "本文提出了一种名为“渐进式语义错觉”的新型矢量素描任务及生成框架，通过序列感知联合优化，实现了单幅素描随笔画增加而发生戏剧性语义转换。"
  },
  {
    "title": "UniT: Unified Multimodal Chain-of-Thought Test-time Scaling",
    "url": "http://arxiv.org/abs/2602.12279v1",
    "abstract_en": "Unified models can handle both multimodal understanding and generation within a single architecture, yet they typically operate in a single pass without iteratively refining their outputs. Many multimodal tasks, especially those involving complex spatial compositions, multiple interacting objects, or evolving instructions, require decomposing instructions, verifying intermediate results, and making iterative corrections. While test-time scaling (TTS) has demonstrated that allocating additional inference compute for iterative reasoning substantially improves language model performance, extending this paradigm to unified multimodal models remains an open challenge. We introduce UniT, a framework for multimodal chain-of-thought test-time scaling that enables a single unified model to reason, verify, and refine across multiple rounds. UniT combines agentic data synthesis, unified model training, and flexible test-time inference to elicit cognitive behaviors including verification, subgoal decomposition, and content memory. Our key findings are: (1) unified models trained on short reasoning trajectories generalize to longer inference chains at test time; (2) sequential chain-of-thought reasoning provides a more scalable and compute-efficient TTS strategy than parallel sampling; (3) training on generation and editing trajectories improves out-of-distribution visual reasoning. These results establish multimodal test-time scaling as an effective paradigm for advancing both generation and understanding in unified models.",
    "date": "2026-02-12",
    "summary_cn": "针对统一多模态模型缺乏迭代优化能力的问题，本文提出UniT框架。该框架利用链式思维进行测试时扩展，使模型能跨越多轮进行推理、验证与修正。研究表明，短轨迹训练可泛化至长推理链，且顺序推理比并行采样更具计算效率，有效提升了模型在复杂任务上的生成与理解性能。",
    "one_sentence": "本文提出了UniT框架，通过结合智能体数据合成、统一模型训练和灵活的测试时推理，首次实现了统一多模态模型的链式思维测试时扩展，使其具备推理、验证和迭代优化的能力。"
  },
  {
    "title": "AttentionRetriever: Attention Layers are Secretly Long Document Retrievers",
    "url": "http://arxiv.org/abs/2602.12278v1",
    "abstract_en": "Retrieval augmented generation (RAG) has been widely adopted to help Large Language Models (LLMs) to process tasks involving long documents. However, existing retrieval models are not designed for long document retrieval and fail to address several key challenges of long document retrieval, including context-awareness, causal dependence, and scope of retrieval. In this paper, we proposed AttentionRetriever, a novel long document retrieval model that leverages attention mechanism and entity-based retrieval to build context-aware embeddings for long document and determine the scope of retrieval. With extensive experiments, we found AttentionRetriever is able to outperform existing retrieval models on long document retrieval datasets by a large margin while remaining as efficient as dense retrieval models.",
    "date": "2026-02-12",
    "summary_cn": "本文提出了一种名为AttentionRetriever的长文档检索模型，通过注意力机制和实体检索构建上下文感知的嵌入，有效解决了长文档检索中的关键问题。实验表明，该模型在长文档检索数据集上显著优于现有模型，且效率与稠密检索模型相当。",
    "one_sentence": "本文提出了一种基于注意力机制和实体检索的长文档检索模型AttentionRetriever，解决了长文档检索中的上下文感知、因果依赖和检索范围等问题。"
  },
  {
    "title": "Reionization Bubbles from Real-Space Cross Correlations of Line Intensity Maps",
    "url": "http://arxiv.org/abs/2602.12277v1",
    "abstract_en": "We propose a new way to reconstruct the ionized-bubble size distribution during the Epoch of Reionization (EoR) through the real-space cross-correlation of 21-cm and star-forming line-intensity maps. Understanding the evolution and timing of the EoR is crucial for both astrophysics and cosmology, and a wealth of information on the first sources can be extracted from the study of ionized bubbles. Nevertheless, directly mapping bubbles is challenging due to the high redshifts involved, possible selection biases, and foregrounds in 21-cm maps. Here, we exploit the real-space cross-correlation $ξ_{21,ν}$ between 21-cm and line-intensity mapping (LIM) signals to reconstruct the evolution of bubble sizes during reionization. For the first time, we show that $ξ_{21,ν}(r)$ departs from a saturation level for each separation $r$ when bubbles of size $r$ begin to form, providing a handle for the onset of bubbles of each radius. Moreover, we demonstrate that $ξ_{21,ν}$ evolves from positive to negative as the EoR progresses, reaching a minimum (i.e. maximum anti-correlation) when bubbles of radius $r$ reach peak abundance. We show that these results are robust to changes in the astrophysical model as well as the timing/topology of reionization. This real-space observable complements usual Fourier-space estimators by capturing the localized nature of bubbles, offering new insights into the sources driving cosmic reionization.",
    "date": "2026-02-12",
    "summary_cn": "该研究提出了一种新方法，通过21厘米和线强度映射信号的实空间互相关$ξ_{21,ν}$重建再电离时期的电离气泡尺度分布。研究发现$ξ_{21,ν}(r)$在气泡形成时偏离饱和水平，并在再电离过程中从正相关演变为反相关，为研究电离气泡演化提供了新见解。该方法对天体物理模型和再电离时序具有鲁棒性，为理解宇宙再电离驱动源提供了新途径。",
    "one_sentence": "本文提出利用21厘米与星系形成线强度图在实空间互相关联重建再电离时期的电离气泡尺度分布。"
  }
]