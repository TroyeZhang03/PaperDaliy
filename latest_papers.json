[
  {
    "title": "Axion misalignment as a synchronization phenomenon",
    "url": "http://arxiv.org/abs/2601.07836v1",
    "abstract_en": "We propose a dynamical reinterpretation of axion misalignment as an emergent collective phenomenon. Drawing an explicit parallel between axion field dynamics and synchronization in coupled oscillator systems, we show that a macroscopic axion phase can arise dynamically from initially incoherent configurations through gradient-driven ordering in an expanding Universe. In this framework, the misalignment angle is not a fundamental initial condition but a collective variable that becomes well defined only once phase coherence develops. Using a simple lattice model, we illustrate how the collective phase is selected prior to the onset of axion oscillations, providing a dynamical basis for the standard misalignment picture. This perspective offers a new way of organizing axion initial-condition sensitivity, reframes anthropic small-angle arguments in terms of phase-ordering efficiency, and suggests a broader connection between fine-tuning and emergent collective dynamics in the early Universe.",
    "date": "2026-01-12",
    "summary_cn": "该研究创新性地将轴子场动力学与耦合振子系统的同步现象进行类比，提出轴子的宏观相位并非一个基本初始条件，而是宇宙膨胀过程中，从初始非相干状态通过梯度驱动自发形成的一种集体涌现变量。通过一个简单的晶格模型，研究展示了集体相位如何在轴子振荡开始前被选定，从而为标准轴子位错图景提供了动力学基础。这一视角为理解轴子初始条件的敏感性提供了新思路，并将人择原理的小角度论证与相位排序效率联系起来，暗示了早期宇宙中精细调节与涌现集体动力学之间可能存在更广泛的联系。",
    "one_sentence": "本文提出将轴子场的初始位错（misalignment）重新解释为宇宙膨胀背景下由梯度驱动的、自发涌现的集体同步现象，而非预设的基本初始条件。"
  },
  {
    "title": "SecureCAI: Injection-Resilient LLM Assistants for Cybersecurity Operations",
    "url": "http://arxiv.org/abs/2601.07835v1",
    "abstract_en": "Large Language Models have emerged as transformative tools for Security Operations Centers, enabling automated log analysis, phishing triage, and malware explanation; however, deployment in adversarial cybersecurity environments exposes critical vulnerabilities to prompt injection attacks where malicious instructions embedded in security artifacts manipulate model behavior. This paper introduces SecureCAI, a novel defense framework extending Constitutional AI principles with security-aware guardrails, adaptive constitution evolution, and Direct Preference Optimization for unlearning unsafe response patterns, addressing the unique challenges of high-stakes security contexts where traditional safety mechanisms prove insufficient against sophisticated adversarial manipulation. Experimental evaluation demonstrates that SecureCAI reduces attack success rates by 94.7% compared to baseline models while maintaining 95.1% accuracy on benign security analysis tasks, with the framework incorporating continuous red-teaming feedback loops enabling dynamic adaptation to emerging attack strategies and achieving constitution adherence scores exceeding 0.92 under sustained adversarial pressure, thereby establishing a foundation for trustworthy integration of language model capabilities into operational cybersecurity workflows and addressing a critical gap in current approaches to AI safety within adversarial domains.",
    "date": "2026-01-12",
    "summary_cn": "大型语言模型在安全运维中心的应用面临提示注入攻击的威胁。本文提出的SecureCAI框架，扩展了宪法AI原则，集成了安全感知护栏、自适应宪法演化以及基于直接偏好优化的不安全响应模式遗忘机制。实验表明，该框架在保持良性任务高准确率的同时，将攻击成功率大幅降低了94.7%，并能通过持续的红队反馈动态适应新攻击策略，为语言模型在对抗性网络安全环境中的可信集成奠定了基础。",
    "one_sentence": "本文提出了一种名为SecureCAI的新型防御框架，通过结合安全护栏、自适应宪法演化和偏好优化等技术，有效抵御对抗性网络安全环境中的提示注入攻击。"
  },
  {
    "title": "A Complete Decomposition of Stochastic Differential Equations",
    "url": "http://arxiv.org/abs/2601.07834v1",
    "abstract_en": "We show that any stochastic differential equation with prescribed time-dependent marginal distributions admits a decomposition into three components: a unique scalar field governing marginal evolution, a symmetric positive-semidefinite diffusion matrix field and a skew-symmetric matrix field.",
    "date": "2026-01-12",
    "summary_cn": "该研究证明，任何具有给定时间依赖边际分布的随机微分方程，都可以被唯一地分解为三个部分：一个控制边际演化的独特标量场、一个对称半正定的扩散矩阵场以及一个反对称矩阵场。这一分解揭示了此类随机过程的内在结构，为理解和构造满足特定边际约束的随机模型提供了新的理论框架。",
    "one_sentence": "本文提出了一种将具有给定时间依赖边际分布的随机微分方程唯一分解为三个组成部分的方法。"
  },
  {
    "title": "Tuning-free Visual Effect Transfer across Videos",
    "url": "http://arxiv.org/abs/2601.07833v1",
    "abstract_en": "We present RefVFX, a new framework that transfers complex temporal effects from a reference video onto a target video or image in a feed-forward manner. While existing methods excel at prompt-based or keyframe-conditioned editing, they struggle with dynamic temporal effects such as dynamic lighting changes or character transformations, which are difficult to describe via text or static conditions. Transferring a video effect is challenging, as the model must integrate the new temporal dynamics with the input video's existing motion and appearance. % To address this, we introduce a large-scale dataset of triplets, where each triplet consists of a reference effect video, an input image or video, and a corresponding output video depicting the transferred effect. Creating this data is non-trivial, especially the video-to-video effect triplets, which do not exist naturally. To generate these, we propose a scalable automated pipeline that creates high-quality paired videos designed to preserve the input's motion and structure while transforming it based on some fixed, repeatable effect. We then augment this data with image-to-video effects derived from LoRA adapters and code-based temporal effects generated through programmatic composition. Building on our new dataset, we train our reference-conditioned model using recent text-to-video backbones. Experimental results demonstrate that RefVFX produces visually consistent and temporally coherent edits, generalizes across unseen effect categories, and outperforms prompt-only baselines in both quantitative metrics and human preference. See our website $\\href{https://tuningfreevisualeffects-maker.github.io/Tuning-free-Visual-Effect-Transfer-across-Videos-Project-Page/}{at\\ this\\ URL}$.",
    "date": "2026-01-12",
    "summary_cn": "本文提出RefVFX框架，旨在解决现有方法难以用文本或静态条件描述的复杂动态视觉特效（如动态光影、角色变换）迁移问题。为训练模型，作者构建了一个大规模三元组数据集，其中包含参考特效视频、输入内容及输出视频，并设计了自动化流水线来生成高质量配对数据。基于此数据集，在现有文生视频模型基础上训练参考条件化模型。实验表明，RefVFX能生成视觉一致、时序连贯的特效，泛化能力强，在定量指标和人工评估中均优于仅基于提示词的基线方法。",
    "one_sentence": "本文提出了RefVFX框架，通过构建大规模视频特效三元组数据集并训练参考视频条件化模型，实现了复杂动态视觉特效从参考视频到目标视频或图像的前馈式迁移。"
  },
  {
    "title": "MHLA: Restoring Expressivity of Linear Attention via Token-Level Multi-Head",
    "url": "http://arxiv.org/abs/2601.07832v1",
    "abstract_en": "While the Transformer architecture dominates many fields, its quadratic self-attention complexity hinders its use in large-scale applications. Linear attention offers an efficient alternative, but its direct application often degrades performance, with existing fixes typically re-introducing computational overhead through extra modules (e.g., depthwise separable convolution) that defeat the original purpose. In this work, we identify a key failure mode in these methods: global context collapse, where the model loses representational diversity. To address this, we propose Multi-Head Linear Attention (MHLA), which preserves this diversity by computing attention within divided heads along the token dimension. We prove that MHLA maintains linear complexity while recovering much of the expressive power of softmax attention, and verify its effectiveness across multiple domains, achieving a 3.6\\% improvement on ImageNet classification, a 6.3\\% gain on NLP, a 12.6\\% improvement on image generation, and a 41\\% enhancement on video generation under the same time complexity.",
    "date": "2026-01-12",
    "summary_cn": "Transformer的自注意力二次复杂度限制了其大规模应用，而现有线性注意力方法常导致性能下降或重新引入计算开销。本文发现这些方法存在“全局上下文坍缩”问题，即模型丧失表征多样性。为此，作者提出了多头线性注意力（MHLA），该方法在令牌维度分割多头并在线性框架内计算注意力，在保持线性复杂度的同时恢复了软注意力的大部分表达能力。实验表明，MHLA在图像分类、自然语言处理、图像生成和视频生成等多个任务上均取得了显著性能提升。",
    "one_sentence": "本文提出了一种名为多头线性注意力（MHLA）的新机制，通过在令牌维度上分割多头并在线性注意力框架内计算注意力，有效解决了线性注意力模型中的全局上下文坍缩问题。"
  }
]