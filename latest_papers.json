[
  {
    "title": "MemFlow: Flowing Adaptive Memory for Consistent and Efficient Long Video Narratives",
    "url": "http://arxiv.org/abs/2512.14699v1",
    "abstract_en": "The core challenge for streaming video generation is maintaining the content consistency in long context, which poses high requirement for the memory design. Most existing solutions maintain the memory by compressing historical frames with predefined strategies. However, different to-generate video chunks should refer to different historical cues, which is hard to satisfy with fixed strategies. In this work, we propose MemFlow to address this problem. Specifically, before generating the coming chunk, we dynamically update the memory bank by retrieving the most relevant historical frames with the text prompt of this chunk. This design enables narrative coherence even if new event happens or scenario switches in future frames. In addition, during generation, we only activate the most relevant tokens in the memory bank for each query in the attention layers, which effectively guarantees the generation efficiency. In this way, MemFlow achieves outstanding long-context consistency with negligible computation burden (7.9% speed reduction compared with the memory-free baseline) and keeps the compatibility with any streaming video generation model with KV cache.",
    "date": "2025-12-16",
    "summary_cn": "本文针对流式视频生成长上下文内容一致性的核心挑战，提出了MemFlow方法。该方法在生成新视频片段前，会根据当前文本提示动态检索并更新记忆库中最相关的历史帧，确保叙事连贯性。生成过程中，仅在注意力层激活记忆库中最相关的令牌，从而以极小的计算开销（相比无记忆基线仅降低7.9%速度）实现了出色的长时一致性，并兼容所有基于KV缓存的流式视频生成模型。",
    "one_sentence": "本文提出了一种名为MemFlow的动态记忆检索与激活方法，通过依据文本提示动态更新和选择性地激活历史帧，在保证生成效率的同时实现了流式视频生成的长上下文一致性。"
  },
  {
    "title": "TimeLens: Rethinking Video Temporal Grounding with Multimodal LLMs",
    "url": "http://arxiv.org/abs/2512.14698v1",
    "abstract_en": "This paper does not introduce a novel method but instead establishes a straightforward, incremental, yet essential baseline for video temporal grounding (VTG), a core capability in video understanding. While multimodal large language models (MLLMs) excel at various video understanding tasks, the recipes for optimizing them for VTG remain under-explored. In this paper, we present TimeLens, a systematic investigation into building MLLMs with strong VTG ability, along two primary dimensions: data quality and algorithmic design. We first expose critical quality issues in existing VTG benchmarks and introduce TimeLens-Bench, comprising meticulously re-annotated versions of three popular benchmarks with strict quality criteria. Our analysis reveals dramatic model re-rankings compared to legacy benchmarks, confirming the unreliability of prior evaluation standards. We also address noisy training data through an automated re-annotation pipeline, yielding TimeLens-100K, a large-scale, high-quality training dataset. Building on our data foundation, we conduct in-depth explorations of algorithmic design principles, yielding a series of meaningful insights and effective yet efficient practices. These include interleaved textual encoding for time representation, a thinking-free reinforcement learning with verifiable rewards (RLVR) approach as the training paradigm, and carefully designed recipes for RLVR training. These efforts culminate in TimeLens models, a family of MLLMs with state-of-the-art VTG performance among open-source models and even surpass proprietary models such as GPT-5 and Gemini-2.5-Flash. All codes, data, and models will be released to facilitate future research.",
    "date": "2025-12-16",
    "summary_cn": "本文针对视频时间定位任务，首先揭示了现有基准数据集的质量问题，并构建了高质量的重标注基准TimeLens-Bench和训练数据集TimeLens-100K。在此基础上，深入探索了算法设计原则，提出了交错文本编码时间表示、免思考的强化学习验证奖励训练范式等有效方法。最终得到的TimeLens模型系列在开源模型中达到了最先进的性能，甚至超越了GPT-5等专有模型。所有代码、数据和模型都将开源。",
    "one_sentence": "本文通过构建高质量基准数据集和提出有效的算法设计原则，系统性地提升了多模态大语言模型的视频时间定位能力。"
  },
  {
    "title": "Spherical Leech Quantization for Visual Tokenization and Generation",
    "url": "http://arxiv.org/abs/2512.14697v1",
    "abstract_en": "Non-parametric quantization has received much attention due to its efficiency on parameters and scalability to a large codebook. In this paper, we present a unified formulation of different non-parametric quantization methods through the lens of lattice coding. The geometry of lattice codes explains the necessity of auxiliary loss terms when training auto-encoders with certain existing lookup-free quantization variants such as BSQ. As a step forward, we explore a few possible candidates, including random lattices, generalized Fibonacci lattices, and densest sphere packing lattices. Among all, we find the Leech lattice-based quantization method, which is dubbed as Spherical Leech Quantization ($Λ_{24}$-SQ), leads to both a simplified training recipe and an improved reconstruction-compression tradeoff thanks to its high symmetry and even distribution on the hypersphere. In image tokenization and compression tasks, this quantization approach achieves better reconstruction quality across all metrics than BSQ, the best prior art, while consuming slightly fewer bits. The improvement also extends to state-of-the-art auto-regressive image generation frameworks.",
    "date": "2025-12-16",
    "summary_cn": "本文通过晶格编码统一了非参数量化方法的框架，揭示了现有无查找量化方法需要辅助损失项的原因。研究探索了多种晶格候选方案，发现基于Leech晶格的量化方法（Λ₂₄-SQ）凭借其高对称性和超球面均匀分布特性，能够简化训练并优化重建与压缩的平衡。在图像标记化和压缩任务中，该方法在消耗更少比特的同时，各项重建指标均优于先前最佳方法BSQ，且改进效果可扩展至先进的自回归图像生成框架。",
    "one_sentence": "本文提出了一种基于Leech晶格（Λ₂₄）的非参数量化方法，其高对称性和超球面上的均匀分布特性简化了训练流程并提升了重建-压缩权衡性能。"
  },
  {
    "title": "CRISP: Contact-Guided Real2Sim from Monocular Video with Planar Scene Primitives",
    "url": "http://arxiv.org/abs/2512.14696v1",
    "abstract_en": "We introduce CRISP, a method that recovers simulatable human motion and scene geometry from monocular video. Prior work on joint human-scene reconstruction relies on data-driven priors and joint optimization with no physics in the loop, or recovers noisy geometry with artifacts that cause motion tracking policies with scene interactions to fail. In contrast, our key insight is to recover convex, clean, and simulation-ready geometry by fitting planar primitives to a point cloud reconstruction of the scene, via a simple clustering pipeline over depth, normals, and flow. To reconstruct scene geometry that might be occluded during interactions, we make use of human-scene contact modeling (e.g., we use human posture to reconstruct the occluded seat of a chair). Finally, we ensure that human and scene reconstructions are physically-plausible by using them to drive a humanoid controller via reinforcement learning. Our approach reduces motion tracking failure rates from 55.2\\% to 6.9\\% on human-centric video benchmarks (EMDB, PROX), while delivering a 43\\% faster RL simulation throughput. We further validate it on in-the-wild videos including casually-captured videos, Internet videos, and even Sora-generated videos. This demonstrates CRISP's ability to generate physically-valid human motion and interaction environments at scale, greatly advancing real-to-sim applications for robotics and AR/VR.",
    "date": "2025-12-16",
    "summary_cn": "CRISP是一种从单目视频中重建可仿真人体运动和场景几何的方法。其核心创新在于通过一个基于深度、法线和光流的简单聚类流程，将平面图元拟合到场景点云上，从而得到干净、凸且适用于仿真的几何体。该方法利用人-场景接触来重建被遮挡的几何部分，并通过强化学习驱动的人形控制器确保重建结果的物理合理性。在多个基准测试上，CRISP将运动跟踪失败率从55.2%大幅降低至6.9%，并提升了43%的仿真效率，在真实世界视频和AI生成视频上都验证了其有效性，有力推动了机器人及AR/VR领域的真实到仿真应用。",
    "one_sentence": "本文提出了一种名为CRISP的新方法，通过将平面图元拟合到场景点云并结合人-场景接触建模，从单目视频中重建出可用于物理仿真的、干净且凸的几何场景和人体运动。"
  },
  {
    "title": "JWST Observations of the Double Nucleus in NGC 4486B: Possible Evidence for a Recent Binary SMBH Merger and Recoil",
    "url": "http://arxiv.org/abs/2512.14695v1",
    "abstract_en": "A recent study of the compact elliptical galaxy NGC 4486B using JWST-NIRSpec IFU kinematics confirmed a supermassive black hole (SMBH) of mass $M_{BH}=3.6\\pm0.7\\times10^8$ (~8% of the stellar mass). In addition to its double nucleus, the nuclear kinematics show pronounced asymmetries: a velocity-dispersion peak displaced by 6 pc from the galaxy center and a ~16 km/s offset in the mean stellar line-of-sight velocity near the SMBH. We examine the origin of the 12 pc double nucleus and these asymmetries and show that the observations favor an SMBH surrounded by an eccentric nuclear disk (END). END formation models require the SMBH to experience a gravitational wave (GW) recoil following a binary SMBH merger. Our orbit-superposition models contain ~50% retrograde stars at the edge of the nuclear region, in striking agreement with END-formation simulations. We infer a pre-merger mass ratio q>0.15 and a recoil kick of ~340 km/s. Our N-body simulations show that with such a kick, the SMBH returns to the center within ~30 Myr. Its flat central core is also consistent with earlier binary black hole scouring. We test two alternative mechanisms-buoyancy-driven oscillations and a pre-merger SMBH binary-but neither reproduces the observed offsets, favoring the GW-kick scenario. Our direct N-body simulations further show that a prograde SMBH binary in a rotating host can stall in a corotation resonance, delaying coalescence. Thus, although NGC 4486B is an old, relaxed galaxy near the Virgo cluster center, its SMBH appears to have merged only recently, making its nucleus a rare nearby laboratory for studying post-merger SMBH dynamics.",
    "date": "2025-12-16",
    "summary_cn": "对椭圆星系NGC 4486B的JWST观测揭示了其双核结构及核区显著的运动不对称性。研究通过轨道叠加模型和N体模拟，证明这些特征最可能由双超大质量黑洞合并后产生的引力波反冲形成偏心核盘所致，并推断出合并质量比大于0.15、反冲速度约340 km/s。该发现表明NGC 4486B是研究黑洞合并后动力学的罕见近邻实验室，并排除了浮力振荡等替代机制。",
    "one_sentence": "本文通过动力学模型与数值模拟，首次提出NGC 4486B星系的核心结构与运动不对称性源于双超大质量黑洞合并产生的引力波反冲，并形成了偏心核盘。"
  }
]