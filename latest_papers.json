[
  {
    "title": "HiStream: Efficient High-Resolution Video Generation via Redundancy-Eliminated Streaming",
    "url": "http://arxiv.org/abs/2512.21338v1",
    "abstract_en": "High-resolution video generation, while crucial for digital media and film, is computationally bottlenecked by the quadratic complexity of diffusion models, making practical inference infeasible. To address this, we introduce HiStream, an efficient autoregressive framework that systematically reduces redundancy across three axes: i) Spatial Compression: denoising at low resolution before refining at high resolution with cached features; ii) Temporal Compression: a chunk-by-chunk strategy with a fixed-size anchor cache, ensuring stable inference speed; and iii) Timestep Compression: applying fewer denoising steps to subsequent, cache-conditioned chunks. On 1080p benchmarks, our primary HiStream model (i+ii) achieves state-of-the-art visual quality while demonstrating up to 76.2x faster denoising compared to the Wan2.1 baseline and negligible quality loss. Our faster variant, HiStream+, applies all three optimizations (i+ii+iii), achieving a 107.5x acceleration over the baseline, offering a compelling trade-off between speed and quality, thereby making high-resolution video generation both practical and scalable.",
    "date": "2025-12-24",
    "summary_cn": "本文针对高分辨率视频生成计算量大的问题，提出高效自回归框架HiStream。该框架通过三重压缩策略降低冗余：在低分辨率去噪后利用缓存特征精修（空间压缩）、分块处理并缓存锚点（时间压缩）、对缓存条件的块减少去噪步数（时间步压缩）。在1080p基准测试中，HiStream在保持顶尖画质的同时，相比基线加速最高达76.2倍，其变体HiStream+更实现了107.5倍加速，实现了速度与质量的有效平衡，使高分辨率视频生成更具实用性和扩展性。",
    "one_sentence": "本文提出HiStream框架，通过空间、时间和时间步三重压缩策略，大幅加速高分辨率视频生成。"
  },
  {
    "title": "Beyond Memorization: A Multi-Modal Ordinal Regression Benchmark to Expose Popularity Bias in Vision-Language Models",
    "url": "http://arxiv.org/abs/2512.21337v1",
    "abstract_en": "We expose a significant popularity bias in state-of-the-art vision-language models (VLMs), which achieve up to 34% higher accuracy on famous buildings compared to ordinary ones, indicating a reliance on memorization over generalizable understanding. To systematically investigate this, we introduce the largest open benchmark for this task: the YearGuessr dataset, a collection of 55,546 building images with multi-modal attributes from 157 countries, annotated with continuous ordinal labels of their construction year (1001-2024), GPS data, and page-view counts as a proxy for popularity. Using this dataset, we frame the construction year prediction task as ordinal regression and introduce popularity-aware interval accuracy metrics to quantify this bias. Our resulting benchmark of 30+ models, including our YearCLIP model, confirms that VLMs excel on popular, memorized items but struggle significantly with unrecognized subjects, exposing a critical flaw in their reasoning capabilities. Project page: https://sytwu.github.io/BeyondMemo/",
    "date": "2025-12-24",
    "summary_cn": "AI 接口暂时不可用，请阅读下方英文摘要。",
    "one_sentence": "生成失败"
  },
  {
    "title": "Optimizing Decoding Paths in Masked Diffusion Models by Quantifying Uncertainty",
    "url": "http://arxiv.org/abs/2512.21336v1",
    "abstract_en": "Masked Diffusion Models (MDMs) offer flexible, non-autoregressive generation, but this freedom introduces a challenge: final output quality is highly sensitive to the decoding order. We are the first to formalize this issue, attributing the variability in output quality to the cumulative predictive uncertainty along a generative path. To quantify this uncertainty, we introduce Denoising Entropy, a computable metric that serves as an internal signal for evaluating generative process. Leveraging this metric, we propose two algorithms designed to optimize the decoding path: a post-hoc selection method and a real-time guidance strategy. Experiments demonstrate that our entropy-guided methods significantly improve generation quality, consistently boosting accuracy on challenging reasoning, planning, and code benchmarks. Our work establishes Denoising Entropy as a principled tool for understanding and controlling generation, effectively turning the uncertainty in MDMs from a liability into a key advantage for discovering high-quality solutions.",
    "date": "2025-12-24",
    "summary_cn": "AI 接口暂时不可用，请阅读下方英文摘要。",
    "one_sentence": "生成失败"
  },
  {
    "title": "Autonomous Uncertainty Quantification for Computational Point-of-care Sensors",
    "url": "http://arxiv.org/abs/2512.21335v1",
    "abstract_en": "Computational point-of-care (POC) sensors enable rapid, low-cost, and accessible diagnostics in emergency, remote and resource-limited areas that lack access to centralized medical facilities. These systems can utilize neural network-based algorithms to accurately infer a diagnosis from the signals generated by rapid diagnostic tests or sensors. However, neural network-based diagnostic models are subject to hallucinations and can produce erroneous predictions, posing a risk of misdiagnosis and inaccurate clinical decisions. To address this challenge, here we present an autonomous uncertainty quantification technique developed for POC diagnostics. As our testbed, we used a paper-based, computational vertical flow assay (xVFA) platform developed for rapid POC diagnosis of Lyme disease, the most prevalent tick-borne disease globally. The xVFA platform integrates a disposable paper-based assay, a handheld optical reader and a neural network-based inference algorithm, providing rapid and cost-effective Lyme disease diagnostics in under 20 min using only 20 uL of patient serum. By incorporating a Monte Carlo dropout (MCDO)-based uncertainty quantification approach into the diagnostics pipeline, we identified and excluded erroneous predictions with high uncertainty, significantly improving the sensitivity and reliability of the xVFA in an autonomous manner, without access to the ground truth diagnostic information of patients. Blinded testing using new patient samples demonstrated an increase in diagnostic sensitivity from 88.2% to 95.7%, indicating the effectiveness of MCDO-based uncertainty quantification in enhancing the robustness of neural network-driven computational POC sensing systems.",
    "date": "2025-12-24",
    "summary_cn": "AI 接口暂时不可用，请阅读下方英文摘要。",
    "one_sentence": "生成失败"
  },
  {
    "title": "Streaming Video Instruction Tuning",
    "url": "http://arxiv.org/abs/2512.21334v1",
    "abstract_en": "We present Streamo, a real-time streaming video LLM that serves as a general-purpose interactive assistant. Unlike existing online video models that focus narrowly on question answering or captioning, Streamo performs a broad spectrum of streaming video tasks, including real-time narration, action understanding, event captioning, temporal event grounding, and time-sensitive question answering. To develop such versatility, we construct Streamo-Instruct-465K, a large-scale instruction-following dataset tailored for streaming video understanding. The dataset covers diverse temporal contexts and multi-task supervision, enabling unified training across heterogeneous streaming tasks. After training end-to-end on the instruction-following dataset through a streamlined pipeline, Streamo exhibits strong temporal reasoning, responsive interaction, and broad generalization across a variety of streaming benchmarks. Extensive experiments show that Streamo bridges the gap between offline video perception models and real-time multimodal assistants, making a step toward unified, intelligent video understanding in continuous video streams.",
    "date": "2025-12-24",
    "summary_cn": "本文介绍了Streamo，一个实时流式视频大模型，旨在作为通用交互助手。不同于现有专注于问答或字幕的模型，Streamo能执行实时叙述、动作理解、事件定位等多种流式任务。为实现此功能，作者构建了包含46.5万条指令的Streamo-Instruct数据集。经端到端训练后，Streamo在时序推理和交互响应上表现出色，弥合了离线视频感知与实时多模态助手间的差距。",
    "one_sentence": "本文提出了Streamo，一个能处理多种实时流式视频任务的端到端视频大模型，并为此构建了专门的指令微调数据集。"
  }
]