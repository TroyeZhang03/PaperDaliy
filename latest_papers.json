[
  {
    "title": "HiStream: Efficient High-Resolution Video Generation via Redundancy-Eliminated Streaming",
    "url": "http://arxiv.org/abs/2512.21338v1",
    "abstract_en": "High-resolution video generation, while crucial for digital media and film, is computationally bottlenecked by the quadratic complexity of diffusion models, making practical inference infeasible. To address this, we introduce HiStream, an efficient autoregressive framework that systematically reduces redundancy across three axes: i) Spatial Compression: denoising at low resolution before refining at high resolution with cached features; ii) Temporal Compression: a chunk-by-chunk strategy with a fixed-size anchor cache, ensuring stable inference speed; and iii) Timestep Compression: applying fewer denoising steps to subsequent, cache-conditioned chunks. On 1080p benchmarks, our primary HiStream model (i+ii) achieves state-of-the-art visual quality while demonstrating up to 76.2x faster denoising compared to the Wan2.1 baseline and negligible quality loss. Our faster variant, HiStream+, applies all three optimizations (i+ii+iii), achieving a 107.5x acceleration over the baseline, offering a compelling trade-off between speed and quality, thereby making high-resolution video generation both practical and scalable.",
    "date": "2025-12-24",
    "summary_cn": "高分辨率视频生成因扩散模型的二次复杂度而计算受限。本文提出了HiStream框架，通过空间压缩（低分辨率去噪并利用缓存特征）、时间压缩（分块策略与锚点缓存）和时间步压缩（缓存条件下的后续块减少去噪步数）来降低冗余。在1080p基准测试中，该方法在保持SOTA画质的同时，相比基线实现了最高107.5倍的加速，使高分辨率视频生成变得实用且可扩展。",
    "one_sentence": "本文提出了一个名为HiStream的自回归框架，通过空间、时间和时间步三重压缩策略，系统性地减少了高分辨率视频生成中的冗余计算。"
  },
  {
    "title": "Beyond Memorization: A Multi-Modal Ordinal Regression Benchmark to Expose Popularity Bias in Vision-Language Models",
    "url": "http://arxiv.org/abs/2512.21337v1",
    "abstract_en": "We expose a significant popularity bias in state-of-the-art vision-language models (VLMs), which achieve up to 34% higher accuracy on famous buildings compared to ordinary ones, indicating a reliance on memorization over generalizable understanding. To systematically investigate this, we introduce the largest open benchmark for this task: the YearGuessr dataset, a collection of 55,546 building images with multi-modal attributes from 157 countries, annotated with continuous ordinal labels of their construction year (1001-2024), GPS data, and page-view counts as a proxy for popularity. Using this dataset, we frame the construction year prediction task as ordinal regression and introduce popularity-aware interval accuracy metrics to quantify this bias. Our resulting benchmark of 30+ models, including our YearCLIP model, confirms that VLMs excel on popular, memorized items but struggle significantly with unrecognized subjects, exposing a critical flaw in their reasoning capabilities. Project page: https://sytwu.github.io/BeyondMemo/",
    "date": "2025-12-24",
    "summary_cn": "AI 接口暂时不可用，请阅读下方英文摘要。",
    "one_sentence": "生成失败"
  },
  {
    "title": "Optimizing Decoding Paths in Masked Diffusion Models by Quantifying Uncertainty",
    "url": "http://arxiv.org/abs/2512.21336v1",
    "abstract_en": "Masked Diffusion Models (MDMs) offer flexible, non-autoregressive generation, but this freedom introduces a challenge: final output quality is highly sensitive to the decoding order. We are the first to formalize this issue, attributing the variability in output quality to the cumulative predictive uncertainty along a generative path. To quantify this uncertainty, we introduce Denoising Entropy, a computable metric that serves as an internal signal for evaluating generative process. Leveraging this metric, we propose two algorithms designed to optimize the decoding path: a post-hoc selection method and a real-time guidance strategy. Experiments demonstrate that our entropy-guided methods significantly improve generation quality, consistently boosting accuracy on challenging reasoning, planning, and code benchmarks. Our work establishes Denoising Entropy as a principled tool for understanding and controlling generation, effectively turning the uncertainty in MDMs from a liability into a key advantage for discovering high-quality solutions.",
    "date": "2025-12-24",
    "summary_cn": "AI 接口暂时不可用，请阅读下方英文摘要。",
    "one_sentence": "生成失败"
  },
  {
    "title": "Autonomous Uncertainty Quantification for Computational Point-of-care Sensors",
    "url": "http://arxiv.org/abs/2512.21335v1",
    "abstract_en": "Computational point-of-care (POC) sensors enable rapid, low-cost, and accessible diagnostics in emergency, remote and resource-limited areas that lack access to centralized medical facilities. These systems can utilize neural network-based algorithms to accurately infer a diagnosis from the signals generated by rapid diagnostic tests or sensors. However, neural network-based diagnostic models are subject to hallucinations and can produce erroneous predictions, posing a risk of misdiagnosis and inaccurate clinical decisions. To address this challenge, here we present an autonomous uncertainty quantification technique developed for POC diagnostics. As our testbed, we used a paper-based, computational vertical flow assay (xVFA) platform developed for rapid POC diagnosis of Lyme disease, the most prevalent tick-borne disease globally. The xVFA platform integrates a disposable paper-based assay, a handheld optical reader and a neural network-based inference algorithm, providing rapid and cost-effective Lyme disease diagnostics in under 20 min using only 20 uL of patient serum. By incorporating a Monte Carlo dropout (MCDO)-based uncertainty quantification approach into the diagnostics pipeline, we identified and excluded erroneous predictions with high uncertainty, significantly improving the sensitivity and reliability of the xVFA in an autonomous manner, without access to the ground truth diagnostic information of patients. Blinded testing using new patient samples demonstrated an increase in diagnostic sensitivity from 88.2% to 95.7%, indicating the effectiveness of MCDO-based uncertainty quantification in enhancing the robustness of neural network-driven computational POC sensing systems.",
    "date": "2025-12-24",
    "summary_cn": "AI 接口暂时不可用，请阅读下方英文摘要。",
    "one_sentence": "生成失败"
  },
  {
    "title": "Streaming Video Instruction Tuning",
    "url": "http://arxiv.org/abs/2512.21334v1",
    "abstract_en": "We present Streamo, a real-time streaming video LLM that serves as a general-purpose interactive assistant. Unlike existing online video models that focus narrowly on question answering or captioning, Streamo performs a broad spectrum of streaming video tasks, including real-time narration, action understanding, event captioning, temporal event grounding, and time-sensitive question answering. To develop such versatility, we construct Streamo-Instruct-465K, a large-scale instruction-following dataset tailored for streaming video understanding. The dataset covers diverse temporal contexts and multi-task supervision, enabling unified training across heterogeneous streaming tasks. After training end-to-end on the instruction-following dataset through a streamlined pipeline, Streamo exhibits strong temporal reasoning, responsive interaction, and broad generalization across a variety of streaming benchmarks. Extensive experiments show that Streamo bridges the gap between offline video perception models and real-time multimodal assistants, making a step toward unified, intelligent video understanding in continuous video streams.",
    "date": "2025-12-24",
    "summary_cn": "本文介绍了Streamo，一个实时流式视频大模型通用助手。与现有专注于特定任务的模型不同，Streamo能处理实时解说、事件定位和时序问答等多种流式任务。为此，作者构建了包含465K样本的Streamo-Instruct数据集。通过端到端训练，Streamo展现了强大的时序推理能力和交互响应性，弥合了离线视频感知与实时多模态助手间的差距。",
    "one_sentence": "本文提出了Streamo，一个基于自建指令数据集训练的、能处理多种实时流式视频任务的统一视频大模型。"
  }
]