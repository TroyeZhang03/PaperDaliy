[
  {
    "title": "On-chip control of the coherence matrix of four-mode partially coherent light: rank, entropy, and modal Stokes parameters",
    "url": "http://arxiv.org/abs/2601.18797v1",
    "abstract_en": "Partially coherent light offers salutary capabilities in optical information processing that cannot be matched by coherent light. To date, this `coherence advantage' has been confirmed in proof-of-principle optical communications protocols using bulk optics. Taking full advantage of such opportunities necessitates processing multimode partially coherent light in integrated photonics platforms that alone provide the requisite stability for cascaded operations on a large scale. Here we demonstrate on-chip manipulation of four-mode partially coherent light described by a $4\\times4$ Hermitian coherence matrix. Starting with generic maximally incoherent light, we utilize an on-chip hexagonal mesh of Mach-Zehnder interferometers to perform all the unitary and non-unitary tasks that are critical for realizing structured coherence: controlling the coherence rank (the number of non-zero eigenvalues of the coherence matrix); tuning the field entropy; molding the structure of the coherence matrix via $4\\times4$ unitary transformations constructed out of sequences of $2\\times2$ unitaries acting on pairs of modes; and tomographic reconstruction of the coherence matrix by measuring the modal Stokes parameters associated with Kronecker Pauli matrices. These results confirm the scalability of utilizing $2\\times2$ on-chip building blocks for the synthesis and reconstruction of high-dimensional coherence matrices, and provide a decisive step towards large-scale on-chip manipulation of massively moded partially coherent light for applications in optical information processing.",
    "date": "2026-01-26",
    "summary_cn": "该论文首次在集成光子平台上实现了对四模部分相干光的片上操控。研究利用马赫-曾德尔干涉仪网络，成功完成了从产生最大非相干光、控制相干矩阵秩和熵、通过2x2酉算符序列构造4x4酉变换以重构相干矩阵结构，到基于模斯托克斯参数对相干矩阵进行层析重建等关键任务。该工作验证了利用片上2x2基础模块合成与重构高维相干矩阵的可行性，是迈向大规模片上部分相干光处理的关键一步。",
    "one_sentence": "本文首次在集成光子芯片上实现了对四模部分相干光的相干矩阵进行生成、操控与重构，为大规模片上光信息处理奠定了基础。"
  },
  {
    "title": "ctELM: Decoding and Manipulating Embeddings of Clinical Trials with Embedding Language Models",
    "url": "http://arxiv.org/abs/2601.18796v1",
    "abstract_en": "Text embeddings have become an essential part of a variety of language applications. However, methods for interpreting, exploring and reversing embedding spaces are limited, reducing transparency and precluding potentially valuable generative use cases. In this work, we align Large Language Models to embeddings of clinical trials using the recently reported Embedding Language Model (ELM) method. We develop an open-source, domain-agnostic ELM architecture and training framework, design training tasks for clinical trials, and introduce an expert-validated synthetic dataset. We then train a series of ELMs exploring the impact of tasks and training regimes. Our final model, ctELM, can accurately describe and compare unseen clinical trials from embeddings alone and produce plausible clinical trials from novel vectors. We further show that generated trial abstracts are responsive to moving embeddings along concept vectors for age and sex of study subjects. Our public ELM implementation and experimental results will aid the alignment of Large Language Models to embedding spaces in the biomedical domain and beyond.",
    "date": "2026-01-26",
    "summary_cn": "文本嵌入模型虽然应用广泛，但其可解释性与可控生成能力有限。本研究利用嵌入语言模型方法，将大语言模型与临床试验的嵌入空间对齐，开发了一个开源、领域无关的模型训练框架。通过引入专家验证的合成数据集并设计针对性训练任务，最终训练的ctELM模型能够仅根据嵌入向量准确描述和比较未见过的临床试验，并能生成合理的新试验。实验还表明，生成的试验摘要可响应年龄、性别等概念向量的变化。该工作为生物医学及其他领域对齐大语言模型与嵌入空间提供了工具与范例。",
    "one_sentence": "本文提出并训练了一个名为ctELM的开放域通用嵌入语言模型，该模型能够根据临床试验的嵌入向量准确生成、描述和比较试验内容，并能响应概念向量生成可控的试验摘要。"
  },
  {
    "title": "Reuse your FLOPs: Scaling RL on Hard Problems by Conditioning on Very Off-Policy Prefixes",
    "url": "http://arxiv.org/abs/2601.18795v1",
    "abstract_en": "Typical reinforcement learning (RL) methods for LLM reasoning waste compute on hard problems, where correct on-policy traces are rare, policy gradients vanish, and learning stalls. To bootstrap more efficient RL, we consider reusing old sampling FLOPs (from prior inference or RL training) in the form of off-policy traces. Standard off-policy methods supervise against off-policy data, causing instabilities during RL optimization. We introduce PrefixRL, where we condition on the prefix of successful off-policy traces and run on-policy RL to complete them, side-stepping off-policy instabilities. PrefixRL boosts the learning signal on hard problems by modulating the difficulty of the problem through the off-policy prefix length. We prove that the PrefixRL objective is not only consistent with the standard RL objective but also more sample efficient. Empirically, we discover back-generalization: training only on prefixed problems generalizes to out-of-distribution unprefixed performance, with learned strategies often differing from those in the prefix. In our experiments, we source the off-policy traces by rejection sampling with the base model, creating a self-improvement loop. On hard reasoning problems, PrefixRL reaches the same training reward 2x faster than the strongest baseline (SFT on off-policy data then RL), even after accounting for the compute spent on the initial rejection sampling, and increases the final reward by 3x. The gains transfer to held-out benchmarks, and PrefixRL is still effective when off-policy traces are derived from a different model family, validating its flexibility in practical settings.",
    "date": "2026-01-26",
    "summary_cn": "针对大型语言模型在困难推理问题上强化学习效率低、梯度消失的问题，本文提出PrefixRL方法。该方法复用旧有计算生成的离策略成功轨迹的前缀，将其作为初始条件进行在策略强化学习来完成后续部分，避免了标准离策略方法的不稳定性。理论证明该方法目标一致且样本效率更高，实验表明其能实现反向泛化，仅使用前缀问题训练即可提升无前缀问题的性能，在困难任务上训练速度更快、最终奖励更高，且具有使用不同模型家族轨迹的灵活性。",
    "one_sentence": "本文提出PrefixRL方法，通过复用离策略轨迹的前缀作为初始条件，并在此基础上进行策略优化，从而高效稳定地强化学习以解决大型语言模型在困难推理问题上的训练停滞问题。"
  },
  {
    "title": "Handling Scope Checks (Extended Version)",
    "url": "http://arxiv.org/abs/2601.18793v1",
    "abstract_en": "Metaprogramming and effect handlers interact in unexpected, and sometimes undesirable, ways. One example is scope extrusion: the generation of ill-scoped code. Scope extrusion can either be preemptively prevented, via static type systems, or retroactively detected, via dynamic checks. Static type systems exist in theory, but struggle with a range of implementation and usability problems in practice. In contrast, dynamic checks exist in practice (e.g. in MetaOCaml), but are understudied in theory. Designers of metalanguages are thus given little guidance regarding the design and implementation of checks. We present the first formal study of dynamic scope extrusion checks, introducing a calculus ($λ_{\\langle\\langle\\text{op}\\rangle\\rangle}$) for describing and evaluating checks. Further, we introduce a novel dynamic check $\\unicode{x2014}$ the \"Cause-for-Concern\" check $\\unicode{x2014}$ which we prove correct, characterise without reference to its implementation, and argue combines the advantages of existing dynamic checks. Finally, we extend our framework with refined environment classifiers, which statically prevent scope extrusion, and compare their expressivity with the dynamic checks.",
    "date": "2026-01-26",
    "summary_cn": "元编程与效应处理器交互时会产生作用域外泄等问题。现有静态类型系统存在实际应用困难，而动态检查（如MetaOCaml中的方法）则缺乏理论研究。本文首次对动态作用域外泄检查进行了形式化研究，提出了一个用于描述和评估检查的演算，并设计了一种名为“Cause-for-Concern”的新型动态检查方法，证明了其正确性，论证了其综合优势。最后，文章还结合了细化的环境分类器这一静态预防方法，并与动态检查进行了表达能力比较。",
    "one_sentence": "本文首次对动态作用域外泄检查进行了形式化研究，提出并证明了一种兼具现有方法优点的新型动态检查算法，并将其与静态方法进行了比较。"
  },
  {
    "title": "MEGnifying Emotion: Sentiment Analysis from Annotated Brain Data",
    "url": "http://arxiv.org/abs/2601.18792v1",
    "abstract_en": "Decoding emotion from brain activity could unlock a deeper understanding of the human experience. While a number of existing datasets align brain data with speech and with speech transcripts, no datasets have annotated brain data with sentiment. To bridge this gap, we explore the use of pre-trained Text-to-Sentiment models to annotate non invasive brain recordings, acquired using magnetoencephalography (MEG), while participants listened to audiobooks. Having annotated the text, we employ force-alignment of the text and audio to align our sentiment labels with the brain recordings. It is straightforward then to train Brainto-Sentiment models on these data. Experimental results show an improvement in balanced accuracy for Brain-to-Sentiment compared to baseline, supporting the proposed approach as a proof-of-concept for leveraging existing MEG datasets and learning to decode sentiment directly from the brain.",
    "date": "2026-01-26",
    "summary_cn": "为填补大脑数据缺乏情感标注的空白，本研究探索了一种新方法：利用预训练的文本情感模型分析受试者聆听有声读物时的语音文本，并通过语音与文本对齐技术将情感标签关联到同步采集的脑磁图（MEG）数据上。基于此标注数据训练的脑到情感解码模型，其平衡准确率优于基线，证明了利用现有MEG数据集直接从大脑活动解码情感的可行性。",
    "one_sentence": "本文提出了一种创新方法，利用预训练的文本情感分析模型，结合语音与文本的对齐技术，为大脑MEG数据生成情感标签，从而首次实现了直接从大脑活动中解码情感的概念验证。"
  }
]