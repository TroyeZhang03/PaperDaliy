[
  {
    "title": "MedMO: Grounding and Understanding Multimodal Large Language Model for Medical Images",
    "url": "http://arxiv.org/abs/2602.06965v1",
    "abstract_en": "Multimodal large language models (MLLMs) have rapidly advanced, yet their adoption in medicine remains limited by gaps in domain coverage, modality alignment, and grounded reasoning. In this work, we introduce MedMO, a medical foundation model built upon a generalized MLLM architecture and trained exclusively on large-scale, domain-specific data. MedMO follows a multi-stage training recipe: (i) cross-modal pretraining to align heterogeneous visual encoders with a medical language backbone; (ii) instruction tuning on multi-task supervision that spans captioning, VQA, report generation, retrieval, and grounded disease localization with bounding boxes; and (iii) reinforcement learning with verifiable rewards that combine factuality checks with a box-level GIoU reward to strengthen spatial grounding and step-by-step reasoning in complex clinical scenarios. MedMO consistently outperforms strong open-source medical MLLMs across multiple modalities and tasks. On VQA benchmarks, MedMO achieves an average accuracy improvement of +13.7% over the baseline and performs within 1.9% of the SOTA Fleming-VL. For text-based QA, it attains +6.9% over the baseline and +14.5% over Fleming-VL. In medical report generation, MedMO delivers significant gains in both semantic and clinical accuracy. Moreover, it exhibits strong grounding capability, achieving an IoU improvement of +40.4 over the baseline and +37.0% over Fleming-VL, underscoring its robust spatial reasoning and localization performance. Evaluations across radiology, ophthalmology, and pathology-microscopy confirm MedMO's broad cross-modality generalization. We release two versions of MedMO: 4B and 8B. Project is available at https://genmilab.github.io/MedMO-Page",
    "date": "2026-02-06",
    "summary_cn": "AI 接口暂时不可用，请阅读下方英文摘要。",
    "one_sentence": "生成失败"
  },
  {
    "title": "Charge-$4e$ superconductor with parafermionic vortices: A path to universal topological quantum computation",
    "url": "http://arxiv.org/abs/2602.06963v1",
    "abstract_en": "Topological superconductors (TSCs) provide a promising route to fault-tolerant quantum information processing. However, the canonical Majorana platform based on $2e$ TSCs remains computationally constrained. In this work, we find a $4e$ TSC that overcomes these constraints by combining a charge-$4e$ condensate with an Abelian chiral $\\mathbb{Z}_3$ topological order in an intertwined fashion. Remarkably, this $4e$ TSC can be obtained by proliferating vortex-antivortex pairs in a stack of two $2e$ $p+ip$ TSCs, or by melting a $ν=2/3$ quantum Hall state. Specific to this TSC, the $hc/(4e)$ fluxes act as charge-conjugation defects in the topological order, whose braiding with anyons transmutes anyons into their antiparticles. This symmetry enrichment leads to $\\mathbb{Z}_3$ parafermion zero modes trapped in the elementary vortex cores, which naturally encode qutrits. Braiding the parafermion defects alone generates the full many-qutrit Clifford group. We further show that a simple single-probe interferometric measurement enables topologically protected magic-state preparation, promoting Clifford operations to a universal gate set. Importantly, the non-Abelian excitations in the $4e$ TSC are confined to externally controlled defects, making them uniquely identifiable and amenable to controlled creation and motion with superconducting-circuit technology. Our results establish hierarchical electron aggregation as a complementary principle for engineering topological quantum matter with enhanced computational power.",
    "date": "2026-02-06",
    "summary_cn": "AI 接口暂时不可用，请阅读下方英文摘要。",
    "one_sentence": "生成失败"
  },
  {
    "title": "Learning a Generative Meta-Model of LLM Activations",
    "url": "http://arxiv.org/abs/2602.06964v1",
    "abstract_en": "Existing approaches for analyzing neural network activations, such as PCA and sparse autoencoders, rely on strong structural assumptions. Generative models offer an alternative: they can uncover structure without such assumptions and act as priors that improve intervention fidelity. We explore this direction by training diffusion models on one billion residual stream activations, creating \"meta-models\" that learn the distribution of a network's internal states. We find that diffusion loss decreases smoothly with compute and reliably predicts downstream utility. In particular, applying the meta-model's learned prior to steering interventions improves fluency, with larger gains as loss decreases. Moreover, the meta-model's neurons increasingly isolate concepts into individual units, with sparse probing scores that scale as loss decreases. These results suggest generative meta-models offer a scalable path toward interpretability without restrictive structural assumptions. Project page: https://generative-latent-prior.github.io.",
    "date": "2026-02-06",
    "summary_cn": "该研究训练扩散模型学习神经网络内部状态分布，发现扩散损失随算力平稳下降且可预测下游效用。元模型的学习先验能提升干预流畅度，且神经元概念稀疏性随损失降低而增强，为无结构假设的神经可解释性提供了可扩展路径。",
    "one_sentence": "本文提出用扩散模型学习神经网络残差流的十亿级激活分布，构建无结构假设的生成式元模型以提升干预保真度和可解释性。"
  },
  {
    "title": "Hard thermal contributions to phase transition observables at NNLO",
    "url": "http://arxiv.org/abs/2602.06962v1",
    "abstract_en": "To construct the high-temperature effective field theory of gauge-Higgs models up to $\\mathcal{O}(g^6)$ in the gauge coupling, we integrate out hard modes to three-loop level and use the next-to-next-to-leading order effective potential. For the Abelian Higgs model, we quantify the impact of both higher-dimensional operators and higher-loop corrections on thermodynamic parameters relevant for gravitational-wave observables, finding that one-loop dimension-six effects typically dominate over two- and three-loop corrections to super-renormalizable parameters for the strongest transitions. We derive the three-loop scalar and Debye masses for the ${\\rm U(1)}$ and ${\\rm SU}(N)$ gauge-Higgs models, as well as the two-loop quartic couplings for the Abelian case, show gauge independence of physical parameters, and demonstrate that no new master integrals are required for the matching, while consistency of 4d and 3d renormalizability points to previously missing contributions in these master integrals.",
    "date": "2026-02-06",
    "summary_cn": "AI 接口暂时不可用，请阅读下方英文摘要。",
    "one_sentence": "生成失败"
  },
  {
    "title": "The N-Body 2PN Hamiltonian and Numerical Integration of the Equations of Motion",
    "url": "http://arxiv.org/abs/2602.06961v1",
    "abstract_en": "To date, the second-order post-Newtonian (2PN) Hamiltonian has been known in closed analytic form only for systems of up to three point masses. In this paper, we present an analytic expression for the general $N$-body 2PN Hamiltonian in the ADM gauge up to a single integral term that, to our knowledge, has no known closed-form analytic solution. We show that the integrals appearing in the 2PN Hamiltonian can be evaluated numerically to machine precision, allowing for cross-validation against analytical results and enabling the full numerical computation of the $N$-body 2PN Hamiltonian. Furthermore, we demonstrate the practical feasibility of the numerical integration of the equations of motion for $N$ bodies at 2PN order using different methods and discuss several strategies for improving computational efficiency.",
    "date": "2026-02-06",
    "summary_cn": "AI 接口暂时不可用，请阅读下方英文摘要。",
    "one_sentence": "生成失败"
  }
]