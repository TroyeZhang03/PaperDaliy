[
  {
    "title": "Reward-free Alignment for Conflicting Objectives",
    "url": "http://arxiv.org/abs/2602.02495v1",
    "abstract_en": "Direct alignment methods are increasingly used to align large language models (LLMs) with human preferences. However, many real-world alignment problems involve multiple conflicting objectives, where naive aggregation of preferences can lead to unstable training and poor trade-offs. In particular, weighted loss methods may fail to identify update directions that simultaneously improve all objectives, and existing multi-objective approaches often rely on explicit reward models, introducing additional complexity and distorting user-specified preferences. The contributions of this paper are two-fold. First, we propose a Reward-free Alignment framework for Conflicted Objectives (RACO) that directly leverages pairwise preference data and resolves gradient conflicts via a novel clipped variant of conflict-averse gradient descent. We provide convergence guarantees to Pareto-critical points that respect user-specified objective weights, and further show that clipping can strictly improve convergence rate in the two-objective setting. Second, we improve our method using some heuristics and conduct experiments to demonstrate the compatibility of the proposed framework for LLM alignment. Both qualitative and quantitative evaluations on multi-objective summarization and safety alignment tasks across multiple LLM families (Qwen 3, Llama 3, Gemma 3) show that our method consistently achieves better Pareto trade-offs compared to existing multi-objective alignment baselines.",
    "date": "2026-02-02",
    "summary_cn": "针对大型语言模型多目标对齐中的目标冲突问题，本文提出了RACO框架。该方法直接利用成对偏好数据，无需显式奖励模型，通过一种新颖的裁剪式冲突规避梯度下降算法解决梯度冲突，并提供收敛性保证。在多个模型系列的摘要和安全对齐任务上的实验表明，该方法能获得更优的帕累托权衡。",
    "one_sentence": "本文提出了一种基于成对偏好数据的无奖励模型多目标对齐框架（RACO），通过裁剪式冲突规避梯度下降解决了目标冲突下的不稳定训练问题。"
  },
  {
    "title": "MEG-XL: Data-Efficient Brain-to-Text via Long-Context Pre-Training",
    "url": "http://arxiv.org/abs/2602.02494v1",
    "abstract_en": "Clinical brain-to-text interfaces are designed for paralysed patients who cannot provide extensive training recordings. Pre-training improves data-efficient generalisation by learning statistical priors across subjects, but these priors critically depend on context. While natural speech might unfold gradually over minutes, most methods pre-train with only a few seconds of context. Thus, we propose MEG-XL, a model pre-trained with 2.5 minutes of MEG context per sample, 5-300x longer than prior work, and equivalent to 191k tokens, capturing extended neural context. Fine-tuning on the task of word decoding from brain data, MEG-XL matches supervised performance with a fraction of the data (e.g. 1hr vs 50hrs) and outperforms brain foundation models. We find that models pre-trained with longer contexts learn representations that transfer better to word decoding. Our results indicate that long-context pre-training helps exploit extended neural context that other methods unnecessarily discard. Code, model weights, and instructions are available at https://github.com/neural-processing-lab/MEG-XL .",
    "date": "2026-02-02",
    "summary_cn": "针对临床脑到文本接口应用中的数据稀缺问题，本研究提出了MEG-XL模型。该模型采用长达2.5分钟的长上下文对MEG信号进行预训练，捕获了更广泛的神经上下文信息。实验表明，在脑电单词解码任务上，MEG-XL仅需少量数据即可达到与传统监督方法相当的性能，并优于现有大脑基础模型，证明了长上下文预训练能有效利用常被忽略的扩展神经信息。",
    "one_sentence": "本文提出了一种名为MEG-XL的脑机接口模型，通过以分钟级长上下文对MEG信号进行预训练，显著提升了数据稀缺条件下大脑活动到文本的解析性能。"
  },
  {
    "title": "PixelGen: Pixel Diffusion Beats Latent Diffusion with Perceptual Loss",
    "url": "http://arxiv.org/abs/2602.02493v1",
    "abstract_en": "Pixel diffusion generates images directly in pixel space in an end-to-end manner, avoiding the artifacts and bottlenecks introduced by VAEs in two-stage latent diffusion. However, it is challenging to optimize high-dimensional pixel manifolds that contain many perceptually irrelevant signals, leaving existing pixel diffusion methods lagging behind latent diffusion models. We propose PixelGen, a simple pixel diffusion framework with perceptual supervision. Instead of modeling the full image manifold, PixelGen introduces two complementary perceptual losses to guide diffusion model towards learning a more meaningful perceptual manifold. An LPIPS loss facilitates learning better local patterns, while a DINO-based perceptual loss strengthens global semantics. With perceptual supervision, PixelGen surpasses strong latent diffusion baselines. It achieves an FID of 5.11 on ImageNet-256 without classifier-free guidance using only 80 training epochs, and demonstrates favorable scaling performance on large-scale text-to-image generation with a GenEval score of 0.79. PixelGen requires no VAEs, no latent representations, and no auxiliary stages, providing a simpler yet more powerful generative paradigm. Codes are publicly available at https://github.com/Zehong-Ma/PixelGen.",
    "date": "2026-02-02",
    "summary_cn": "传统的像素扩散方法因直接优化高维像素空间而面临挑战，性能落后于潜在扩散模型。本文提出了PixelGen，一个引入感知监督的简单像素扩散框架。该框架通过结合LPIPS损失和基于DINO的感知损失，分别引导模型学习更好的局部模式和全局语义，从而聚焦于更有意义的感知流形。该方法无需变分自编码器、潜在表示或辅助阶段，在ImageNet-256和文本到图像生成任务上均取得了优异的性能，实现了更简洁而强大的生成范式。",
    "one_sentence": "本文提出了一种名为PixelGen的像素扩散框架，通过引入感知损失函数来引导模型学习更有效的图像表示，从而在简化生成流程的同时超越了潜在扩散模型的性能。"
  },
  {
    "title": "Spherical representations of unitary groups at ramified places and the arithmetic inner product formula",
    "url": "http://arxiv.org/abs/2602.02492v1",
    "abstract_en": "In this article, we study admissible representations of even unitary groups over local fields, where the quadratic extension is ramified, with invariant vectors under the action of the stabilizer of a unimodular lattice and some properties of the corresponding integral model of unitary Shimura varieties. As a direct application, we are able to improve the arithmetic inner product formula so that the places with local root number \\((-1)\\) are allowed to be ramified.",
    "date": "2026-02-02",
    "summary_cn": "本文研究了在二次扩张分歧的局部域上，偶幺正群关于一个幺模格稳定子具有不变向量的容许表示，并探讨了相关幺正志村簇积分模型的性质。基于此，作者推广了算术内积公式，使其能处理局部根数为 (-1) 的位点本身存在分歧的情况，从而扩展了公式的应用范围。",
    "one_sentence": "本文通过研究局部域上偶幺正群在特定稳定子作用下有不变向量的容许表示及相关积分模型，推广了算术内积公式，使其适用于局部根数为 (-1) 的位点发生分歧的情形。"
  },
  {
    "title": "Secure Multi-User Linearly-Separable Distributed Computing",
    "url": "http://arxiv.org/abs/2602.02489v1",
    "abstract_en": "The introduction of the new multi-user linearly-separable distributed computing framework, has recently revealed how a parallel treatment of users can yield large parallelization gains with relatively low computation and communication costs. These gains stem from a new approach that converts the computing problem into a sparse matrix factorization problem; a matrix $F$ that describes the users' requests, is decomposed as \\(F = DE\\), where a \\(γ\\)-sparse \\(E\\) defines the task allocation across $N$ servers, and a \\(δ\\)-sparse \\(D\\) defines the connectivity between \\(N\\) servers and \\(K\\) users as well as the decoding process. While this approach provides near-optimal performance, its linear nature has raised data secrecy concerns.   We here adopt an information-theoretic secrecy framework, seeking guarantees that each user can learn nothing more than its own requested function. In this context, our main result provides two necessary and sufficient secrecy criteria; (i) for each user \\(k\\) who observes $α_k$ server responses, the common randomness visible to that user must span a subspace of dimension exactly $α_k-1$,   and (ii) for each user, removing from \\(\\mathbf{D}\\) the columns corresponding to the servers it observes must leave a matrix of rank at least \\(K-1\\). With these conditions in place, we design a general scheme -- that applies to finite and non-finite fields alike -- which is based on appending to \\(\\mathbf{E}\\) a basis of \\(\\mathrm{Null}(\\mathbf{D})\\) and by carefully injecting shared randomness. In many cases, this entails no additional costs. The scheme, while maintaining performance, guarantees perfect information-theoretic secrecy in the case of finite fields, while in the real case, the conditions yield an explicit mutual-information bound that can be made arbitrarily small by increasing the variance of Gaussian common randomness.",
    "date": "2026-02-02",
    "summary_cn": "针对新兴的线性可分分布式计算框架存在的数据泄露风险，本文首次从信息论角度研究了其安全问题，目标是确保每个用户只能获取自身请求的函数信息。核心贡献在于提出了两个保证信息安全的充要条件，并基于此设计了一种通用的加密方案。该方案通过向任务分配矩阵附加特定零空间基向量并精心注入共享随机性来实现，对于有限域能保证完美保密性，对于实数域则可获得任意小的互信息泄露。重要的是，该方案在多种情况下无需增加额外的计算或通信开销，即可在保障性能的同时提升系统安全性。",
    "one_sentence": "本文为线性可分分布式计算框架提出了两个信息论安全的充要准则，并设计了一种无需牺牲性能即可保证完美或渐进安全性的通用加密方案。"
  }
]